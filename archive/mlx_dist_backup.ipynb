{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb8b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Use the magic command without code block formatting\n",
    "# %pip install mlx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e2e5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python -m ipykernel install --user --name mlx-distributed --display-name \"MLX Distributed (arm64)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f742fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Remove existing environment if it exists\n",
    "conda env remove -n mlx-distributed -y 2>/dev/null || true\n",
    "\n",
    "# Create fresh environment with Python 3.11 (optimal for MLX)\n",
    "CONDA_SUBDIR=osx-arm64 conda create -n mlx-distributed python=3.11 -y\n",
    "\n",
    "# Activate and configure for ARM64\n",
    "\n",
    "conda activate mlx-distributed\n",
    "conda config --env --set subdir osx-arm64\n",
    "\n",
    "echo \"Environment created successfully!\"\n",
    "conda info --envs | grep mlx-distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d512e554",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Activate environment\n",
    "source ~/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate mlx-distributed\n",
    "\n",
    "# Install OpenMPI via conda (not homebrew!)\n",
    "conda install -c conda-forge openmpi -y\n",
    "\n",
    "# Install mpi4py\n",
    "conda install -c conda-forge mpi4py -y\n",
    "\n",
    "# Install MLX and MLX-LM\n",
    "pip install mlx mlx-lm\n",
    "\n",
    "# Install additional utilities\n",
    "pip install numpy jupyter ipykernel\n",
    "\n",
    "# Add kernel to Jupyter\n",
    "python -m ipykernel install --user --name mlx-distributed --display-name \"MLX Distributed\"\n",
    "\n",
    "echo \"Installation complete!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3474418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "print(\"=== System Information ===\")\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print()\n",
    "\n",
    "print(\"=== MLX Installation ===\")\n",
    "try:\n",
    "    import mlx\n",
    "    import mlx.core as mx\n",
    "    print(f\"‚úì MLX version: {mlx.__version__}\")\n",
    "    print(f\"‚úì Metal available: {mx.metal.is_available()}\")\n",
    "    print(f\"‚úì Default device: {mx.default_device()}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó MLX error: {e}\")\n",
    "print()\n",
    "\n",
    "print(\"=== MPI Installation ===\")\n",
    "try:\n",
    "    from mpi4py import MPI\n",
    "    print(f\"‚úì mpi4py version: {MPI.Get_version()}\")\n",
    "    print(f\"‚úì MPI vendor: {MPI.get_vendor()}\")\n",
    "    \n",
    "    # Check MPI executable\n",
    "    result = subprocess.run(['which', 'mpirun'], capture_output=True, text=True)\n",
    "    print(f\"‚úì mpirun location: {result.stdout.strip()}\")\n",
    "    \n",
    "    # Check MPI version - fix for f-string issue\n",
    "    result = subprocess.run(['mpirun', '--version'], capture_output=True, text=True)\n",
    "    first_line = result.stdout.strip().split('\\n')[0]  # Move split outside f-string\n",
    "    print(f\"‚úì MPI version: {first_line}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó MPI error: {e}\")\n",
    "print()\n",
    "\n",
    "print(\"=== MLX-LM Installation ===\")\n",
    "try:\n",
    "    import mlx_lm\n",
    "    print(\"‚úì mlx_lm installed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó mlx_lm error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c05722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "import time\n",
    "\n",
    "# Set GPU as default device\n",
    "mx.set_default_device(mx.gpu)\n",
    "\n",
    "print(\"=== GPU Test ===\")\n",
    "print(f\"Default device: {mx.default_device()}\")\n",
    "print(f\"Metal available: {mx.metal.is_available()}\")\n",
    "\n",
    "# Create a large array to test GPU\n",
    "size = 10000\n",
    "print(f\"\\nCreating {size}x{size} matrix multiplication...\")\n",
    "\n",
    "# Time CPU vs GPU\n",
    "start = time.time()\n",
    "a = mx.random.uniform(shape=(size, size))\n",
    "b = mx.random.uniform(shape=(size, size))\n",
    "c = a @ b\n",
    "mx.eval(c)  # Force evaluation\n",
    "gpu_time = time.time() - start\n",
    "\n",
    "print(f\"GPU computation time: {gpu_time:.3f} seconds\")\n",
    "print(f\"GPU memory used: {mx.metal.get_active_memory() / 1024**3:.2f} GB\")\n",
    "print(f\"GPU memory cache: {mx.metal.get_cache_memory() / 1024**3:.2f} GB\")\n",
    "\n",
    "# Test small model loading\n",
    "print(\"\\n=== Testing Model Loading ===\")\n",
    "try:\n",
    "    from mlx_lm import load\n",
    "    model, tokenizer = load(\"mlx-community/Llama-3.2-1B-Instruct-4bit\")\n",
    "    print(\"‚úì Model loaded successfully\")\n",
    "    \n",
    "    # Quick inference test\n",
    "    prompt = \"Hello\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"np\")\n",
    "    print(f\"‚úì Tokenizer works: '{prompt}' -> {inputs['input_ids']}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚úó Model loading error: {e}\")\n",
    "    print(\"This is okay for now - we'll use a different model for distributed tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd0158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "hosts = [\"mm@mm1.local\", \"mm@mm2.local\"]\n",
    "\n",
    "print(\"=== Testing SSH Connectivity ===\")\n",
    "for host in hosts:\n",
    "    print(f\"\\nTesting {host}...\")\n",
    "    \n",
    "    # Test basic SSH\n",
    "    result = subprocess.run(\n",
    "        [\"ssh\", \"-o\", \"BatchMode=yes\", \"-o\", \"ConnectTimeout=5\", host, \"echo 'SSH OK'\"],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"‚úì SSH connection successful\")\n",
    "    else:\n",
    "        print(f\"‚úó SSH connection failed: {result.stderr}\")\n",
    "        print(f\"  Fix: Run 'ssh-copy-id {host}' in terminal\")\n",
    "\n",
    "# Create SSH config for faster connections\n",
    "ssh_config = \"\"\"\n",
    "Host mm1.local\n",
    "    User mm\n",
    "    HostName mm1.local\n",
    "    ForwardAgent yes\n",
    "    ServerAliveInterval 60\n",
    "\n",
    "Host mm2.local\n",
    "    User mm\n",
    "    HostName mm2.local\n",
    "    ForwardAgent yes\n",
    "    ServerAliveInterval 60\n",
    "\n",
    "Host *\n",
    "    AddKeysToAgent yes\n",
    "    UseKeychain yes\n",
    "    IdentityFile ~/.ssh/id_rsa\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n=== Recommended SSH Config ===\")\n",
    "print(\"Add this to ~/.ssh/config:\")\n",
    "print(ssh_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd038fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check if mpi4py is installed in current environment\n",
    "try:\n",
    "    import mpi4py\n",
    "    print(f\"‚úì mpi4py is installed in current Python: {mpi4py.__file__}\")\n",
    "    print(f\"  mpi4py version: {mpi4py.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"‚úó mpi4py not found in current Python\")\n",
    "\n",
    "# Check which Python we're using\n",
    "print(f\"\\nCurrent Python: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Better way to check installed packages\n",
    "try:\n",
    "    import pkg_resources\n",
    "    installed_packages = [d.project_name for d in pkg_resources.working_set]\n",
    "    if 'mpi4py' in installed_packages:\n",
    "        version = pkg_resources.get_distribution('mpi4py').version\n",
    "        print(f\"\\n‚úì mpi4py {version} is installed via pip\")\n",
    "    else:\n",
    "        print(\"\\n‚úó mpi4py not found in pip packages\")\n",
    "except:\n",
    "    # Alternative method\n",
    "    import importlib.metadata\n",
    "    try:\n",
    "        version = importlib.metadata.version('mpi4py')\n",
    "        print(f\"\\n‚úì mpi4py {version} is installed\")\n",
    "    except:\n",
    "        print(\"\\n‚úó mpi4py not installed\")\n",
    "\n",
    "# Check conda list instead\n",
    "import subprocess\n",
    "result = subprocess.run(['conda', 'list', 'mpi4py'], capture_output=True, text=True)\n",
    "print(f\"\\nConda list output:\\n{result.stdout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304fc6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=== Solution: Use Homebrew MPI ===\")\n",
    "\n",
    "# First, uninstall the broken mpi4py\n",
    "print(\"1. Removing broken mpi4py...\")\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'uninstall', 'mpi4py', '-y'])\n",
    "\n",
    "# Install mpi4py compiled against Homebrew's MPI\n",
    "print(\"\\n2. Installing mpi4py with Homebrew MPI...\")\n",
    "env = os.environ.copy()\n",
    "env['MPICC'] = '/opt/homebrew/bin/mpicc'\n",
    "env['CC'] = '/opt/homebrew/bin/mpicc'\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, '-m', 'pip', 'install', 'mpi4py', '--no-cache-dir', '--no-binary', 'mpi4py'],\n",
    "    capture_output=True, text=True, env=env\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úì mpi4py installed successfully\")\n",
    "else:\n",
    "    print(f\"Installation output: {result.stdout}\")\n",
    "    print(f\"Errors: {result.stderr}\")\n",
    "\n",
    "# Test the installation\n",
    "print(\"\\n3. Testing MPI...\")\n",
    "test_script = \"\"\"\n",
    "import sys\n",
    "print(f\"Python: {sys.executable}\")\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "print(f\"Rank {rank}/{size}: MPI is working!\")\n",
    "\n",
    "if rank == 0 and size > 1:\n",
    "    comm.send(\"Hello from rank 0\", dest=1)\n",
    "elif rank == 1:\n",
    "    msg = comm.recv(source=0)\n",
    "    print(f\"Rank 1 received: {msg}\")\n",
    "\"\"\"\n",
    "\n",
    "with open('test_mpi_final.py', 'w') as f:\n",
    "    f.write(test_script)\n",
    "\n",
    "# Run with Homebrew's mpirun\n",
    "result = subprocess.run(\n",
    "    ['/opt/homebrew/bin/mpirun', '-np', '2', sys.executable, 'test_mpi_final.py'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "print(\"\\nOutput:\")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)\n",
    "\n",
    "os.remove('test_mpi_final.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d333eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create configuration for using Homebrew MPI\n",
    "config_content = f\"\"\"#!/bin/bash\n",
    "# MLX Distributed Configuration\n",
    "\n",
    "# Use Homebrew MPI\n",
    "export PATH=\"/opt/homebrew/bin:$PATH\"\n",
    "export MPICC=/opt/homebrew/bin/mpicc\n",
    "export MPIRUN=/opt/homebrew/bin/mpirun\n",
    "\n",
    "# Python from conda environment\n",
    "export PYTHON={sys.executable}\n",
    "\n",
    "# Function to run distributed MLX\n",
    "run_mlx_dist() {{\n",
    "    /opt/homebrew/bin/mpirun \"$@\"\n",
    "}}\n",
    "\n",
    "echo \"MLX Distributed configured with:\"\n",
    "echo \"  MPI: Homebrew OpenMPI 5.0.7\"\n",
    "echo \"  Python: Conda environment (mlx-distributed)\"\n",
    "echo \"\"\n",
    "echo \"Usage: run_mlx_dist -np 4 python your_script.py\"\n",
    "\"\"\"\n",
    "\n",
    "with open('mlx_dist_config.sh', 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "os.chmod('mlx_dist_config.sh', 0o755)\n",
    "\n",
    "print(\"\\n=== Configuration Created ===\")\n",
    "print(\"Source this before running distributed jobs:\")\n",
    "print(\"  source mlx_dist_config.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e7c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "mlx_launch = '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch'\n",
    "\n",
    "print(\"=== Creating Final Working Scripts ===\")\n",
    "\n",
    "# Local run script with MPI backend\n",
    "local_script = f\"\"\"#!/bin/bash\n",
    "# Run MLX distributed locally with MPI backend\n",
    "\n",
    "NP=\"${{1:-2}}\"\n",
    "SCRIPT=\"${{2:-test_mlx_dist.py}}\"\n",
    "\n",
    "echo \"Running MLX locally with $NP processes (MPI backend)...\"\n",
    "echo \"Script: $SCRIPT\"\n",
    "echo \"\"\n",
    "\n",
    "{mlx_launch} --backend mpi --hosts localhost -n \"$NP\" \"$SCRIPT\"\n",
    "\"\"\"\n",
    "\n",
    "with open('run_mlx_local.sh', 'w') as f:\n",
    "    f.write(local_script)\n",
    "os.chmod('run_mlx_local.sh', 0o755)\n",
    "\n",
    "# Distributed run script for your cluster\n",
    "distributed_script = f\"\"\"#!/bin/bash\n",
    "# Run MLX distributed across your Mac cluster\n",
    "\n",
    "SCRIPT=\"${{1:-test_mlx_dist.py}}\"\n",
    "PROCESSES_PER_HOST=\"${{2:-2}}\"\n",
    "\n",
    "echo \"Running MLX distributed (MPI backend)\"\n",
    "echo \"Hosts: mbp.local, mm1.local, mm2.local\"\n",
    "echo \"Processes per host: $PROCESSES_PER_HOST\"\n",
    "echo \"Script: $SCRIPT\"\n",
    "echo \"\"\n",
    "\n",
    "{mlx_launch} --backend mpi \\\\\n",
    "    --hosts mbp.local,mm1.local,mm2.local \\\\\n",
    "    -n \"$PROCESSES_PER_HOST\" \\\\\n",
    "    \"$SCRIPT\"\n",
    "\"\"\"\n",
    "\n",
    "with open('run_mlx_distributed.sh', 'w') as f:\n",
    "    f.write(distributed_script)\n",
    "os.chmod('run_mlx_distributed.sh', 0o755)\n",
    "\n",
    "# Create hostfile for MPI backend\n",
    "hostfile_content = \"\"\"mbp.local\n",
    "mbp.local\n",
    "mm1.local\n",
    "mm1.local\n",
    "mm2.local\n",
    "mm2.local\n",
    "\"\"\"\n",
    "\n",
    "with open('mlx_hostfile.txt', 'w') as f:\n",
    "    f.write(hostfile_content)\n",
    "\n",
    "# Hostfile version\n",
    "hostfile_script = f\"\"\"#!/bin/bash\n",
    "# Run MLX using hostfile (MPI backend)\n",
    "\n",
    "SCRIPT=\"${{1:-test_mlx_dist.py}}\"\n",
    "HOSTFILE=\"${{2:-mlx_hostfile.txt}}\"\n",
    "\n",
    "echo \"Running MLX with hostfile (MPI backend)\"\n",
    "echo \"Hostfile: $HOSTFILE\"\n",
    "echo \"Script: $SCRIPT\"\n",
    "echo \"\"\n",
    "\n",
    "{mlx_launch} --backend mpi --hostfile \"$HOSTFILE\" \"$SCRIPT\"\n",
    "\"\"\"\n",
    "\n",
    "with open('run_mlx_hostfile.sh', 'w') as f:\n",
    "    f.write(hostfile_script)\n",
    "os.chmod('run_mlx_hostfile.sh', 0o755)\n",
    "\n",
    "print(\"Created working scripts!\")\n",
    "print(\"\\n‚úÖ Test locally first:\")\n",
    "print(\"   ./run_mlx_local.sh 4\")\n",
    "print(\"\\n‚úÖ Then run distributed:\")\n",
    "print(\"   ./run_mlx_distributed.sh\")\n",
    "print(\"   # This will run 2 processes on each of your 3 Macs (6 total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f8687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive distributed test\n",
    "comprehensive_test = \"\"\"\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import socket\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialize distributed\n",
    "world = mx.distributed.init()\n",
    "rank = world.rank()\n",
    "size = world.size()\n",
    "hostname = socket.gethostname()\n",
    "pid = os.getpid()\n",
    "\n",
    "# Set GPU\n",
    "mx.set_default_device(mx.gpu)\n",
    "\n",
    "print(f\"[Rank {rank}/{size}] Process {pid} on {hostname}\")\n",
    "print(f\"[Rank {rank}] GPU: {mx.metal.is_available()}\")\n",
    "print(f\"[Rank {rank}] Device: {mx.default_device()}\")\n",
    "\n",
    "# Synchronize before tests\n",
    "mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"Running MLX Distributed Tests\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Test 1: Basic all-reduce\n",
    "if rank == 0:\n",
    "    print(\"\\\\n1. Testing all-reduce...\")\n",
    "    \n",
    "local_value = mx.array([float(rank)])\n",
    "sum_result = mx.distributed.all_sum(local_value)\n",
    "mx.eval(sum_result)\n",
    "\n",
    "if rank == 0:\n",
    "    expected = sum(range(size))\n",
    "    print(f\"   All-reduce sum: {sum_result.item()} (expected: {expected})\")\n",
    "    print(f\"   {'‚úì PASSED' if abs(sum_result.item() - expected) < 0.001 else '‚úó FAILED'}\")\n",
    "\n",
    "# Test 2: Model parameter synchronization\n",
    "if rank == 0:\n",
    "    print(\"\\\\n2. Testing model parameter sync...\")\n",
    "\n",
    "model = nn.Linear(100, 10)\n",
    "mx.eval(model.parameters())\n",
    "\n",
    "# Get initial param sum\n",
    "param_sum_before = sum(p.sum().item() for _, p in model.parameters())\n",
    "print(f\"[Rank {rank}] Initial param sum: {param_sum_before:.6f}\")\n",
    "\n",
    "# Synchronize parameters\n",
    "for _, p in model.parameters():\n",
    "    p_synced = mx.distributed.all_sum(p) / size\n",
    "    p[:] = p_synced\n",
    "\n",
    "mx.eval(model.parameters())\n",
    "param_sum_after = sum(p.sum().item() for _, p in model.parameters())\n",
    "\n",
    "# All ranks should have same param sum now\n",
    "all_sums = mx.distributed.all_sum(mx.array([param_sum_after]))\n",
    "mx.eval(all_sums)\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"   Synchronized param sum: {param_sum_after:.6f}\")\n",
    "    print(f\"   {'‚úì PASSED' if all_sums.item() == param_sum_after * size else '‚úó FAILED'}\")\n",
    "\n",
    "# Test 3: Bandwidth test\n",
    "if rank == 0:\n",
    "    print(\"\\\\n3. Testing bandwidth...\")\n",
    "\n",
    "size_mb = 10\n",
    "data = mx.random.uniform(shape=(size_mb * 1024 * 1024 // 4,))\n",
    "\n",
    "start = time.time()\n",
    "result = mx.distributed.all_sum(data)\n",
    "mx.eval(result)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "bandwidth = size_mb * size / elapsed\n",
    "if rank == 0:\n",
    "    print(f\"   Data size: {size_mb}MB per rank\")\n",
    "    print(f\"   Time: {elapsed:.3f}s\")\n",
    "    print(f\"   Bandwidth: {bandwidth:.1f} MB/s\")\n",
    "\n",
    "# Final status\n",
    "mx.eval(mx.distributed.all_sum(mx.array([1.0])))  # Sync\n",
    "if rank == 0:\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"‚úì All tests completed successfully!\")\n",
    "    print(\"=\"*50)\n",
    "\"\"\"\n",
    "\n",
    "with open('test_mlx_comprehensive.py', 'w') as f:\n",
    "    f.write(comprehensive_test)\n",
    "\n",
    "print(\"\\n=== Setup Complete! ===\")\n",
    "print(\"\\nüéâ MLX distributed is working correctly!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Test comprehensive script locally:\")\n",
    "print(\"   ./run_mlx_local.sh 4 test_mlx_comprehensive.py\")\n",
    "print(\"\\n2. Deploy environment to mm1.local and mm2.local\")\n",
    "print(\"   (They need the same mlx-distributed conda environment)\")\n",
    "print(\"\\n3. Run distributed across your cluster:\")\n",
    "print(\"   ./run_mlx_distributed.sh test_mlx_comprehensive.py\")\n",
    "print(\"\\nThis will run 6 processes total (2 on each Mac)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ab8c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import mlx.core as mx\n",
    "from mlx_lm import load, generate\n",
    "\n",
    "\n",
    "def main():\n",
    "    world = mx.distributed.init()\n",
    "    rank = world.rank()\n",
    "    size = world.size()\n",
    "\n",
    "    mx.set_default_device(mx.gpu)\n",
    "\n",
    "    if rank == 0:\n",
    "        print(f\"Running on {size} processes\")\n",
    "\n",
    "    model, tokenizer = load(\"mlx-community/Llama-3.2-1B-Instruct-4bit\")\n",
    "    prompt = f\"Hello from rank {rank}!\"\n",
    "    result = generate(model, tokenizer, prompt, max_tokens=20)\n",
    "\n",
    "    print(f\"[{rank}/{size} on {socket.gethostname()}] {result}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077b5d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlx.core as mx\n",
    "from mlx_lm import load, generate\n",
    "import socket\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    # Initialize distributed\n",
    "    world = mx.distributed.init()\n",
    "    rank = world.rank()\n",
    "    size = world.size()\n",
    "    hostname = socket.gethostname()\n",
    "    \n",
    "    # Set GPU\n",
    "    mx.set_default_device(mx.gpu)\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"=== MLX Distributed Inference ===\")\n",
    "        print(f\"Running on {size} processes\")\n",
    "        print(f\"Hosts: {', '.join([f'rank{i}' for i in range(size)])}\")\n",
    "        print(\"=\"*40)\n",
    "    \n",
    "    # Each rank loads the model\n",
    "    if rank == 0:\n",
    "        print(\"\\nLoading model on all ranks...\")\n",
    "    \n",
    "    start = time.time()\n",
    "    model, tokenizer = load(\"mlx-community/Llama-3.2-1B-Instruct-4bit\")\n",
    "    load_time = time.time() - start\n",
    "    \n",
    "    print(f\"[Rank {rank}/{hostname}] Model loaded in {load_time:.2f}s\")\n",
    "    \n",
    "    # Synchronize after loading\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    # Different prompts for each rank\n",
    "    prompts = [\n",
    "        \"The future of artificial intelligence is\",\n",
    "        \"Machine learning helps us to\",\n",
    "        \"The most important technology today is\",\n",
    "        \"Distributed computing enables\",\n",
    "        \"Apple Silicon chips are\",\n",
    "        \"The best programming language is\"\n",
    "    ]\n",
    "    \n",
    "    prompt = prompts[rank % len(prompts)]\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"\\n=== Generating Responses ===\")\n",
    "    \n",
    "    # Generate response\n",
    "    start = time.time()\n",
    "    result = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt, \n",
    "        max_tokens=50,\n",
    "        # temp=0.7\n",
    "    )\n",
    "    gen_time = time.time() - start\n",
    "    \n",
    "    # Print results in order\n",
    "    for i in range(size):\n",
    "        if rank == i:\n",
    "            print(f\"\\n[Rank {rank}/{hostname}]\")\n",
    "            print(f\"Prompt: {prompt}\")\n",
    "            print(f\"Response: {result}\")\n",
    "            print(f\"Generation time: {gen_time:.2f}s\")\n",
    "        mx.eval(mx.distributed.all_sum(mx.array([1.0])))  # Sync barrier\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(\"\\n=== Inference Complete ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f482d8",
   "metadata": {},
   "source": [
    "Example from WWDC25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import mlx.core as mx\n",
    "from mlx_lm import load, generate\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "\n",
    "def setup_mlx_environment() -> None:\n",
    "    \"\"\"Configure MLX for optimal performance.\"\"\"\n",
    "    # Set GPU as default device for better performance\n",
    "    mx.set_default_device(mx.gpu)\n",
    "    \n",
    "    print(\"=== MLX Environment Setup ===\")\n",
    "    print(f\"Device: {mx.default_device()}\")\n",
    "    print(f\"Metal available: {mx.metal.is_available()}\")\n",
    "    if mx.metal.is_available():\n",
    "        print(f\"GPU memory: {mx.metal.get_active_memory() / 1024**3:.2f} GB active\")\n",
    "        print(f\"GPU cache: {mx.metal.get_cache_memory() / 1024**3:.2f} GB cached\")\n",
    "    print()\n",
    "\n",
    "\n",
    "def load_model_with_monitoring(model_name: str) -> tuple:\n",
    "    \"\"\"Load model with performance monitoring and error handling.\"\"\"\n",
    "    print(f\"Loading model: {model_name}\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        model, tokenizer = load(model_name)\n",
    "        load_time = time.time() - start_time\n",
    "        \n",
    "        print(f\"‚úì Model loaded successfully in {load_time:.2f}s\")\n",
    "        \n",
    "        # Check model info\n",
    "        if hasattr(model, 'config'):\n",
    "            config = model.config\n",
    "            print(f\"  Model type: {getattr(config, 'model_type', 'Unknown')}\")\n",
    "            print(f\"  Vocab size: {getattr(config, 'vocab_size', 'Unknown')}\")\n",
    "            print(f\"  Hidden size: {getattr(config, 'hidden_size', 'Unknown')}\")\n",
    "        \n",
    "        return model, tokenizer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error loading model: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def create_chat_messages(user_prompt: str, system_prompt: Optional[str] = None) -> List[Dict[str, str]]:\n",
    "    \"\"\"Create properly formatted chat messages.\"\"\"\n",
    "    messages = []\n",
    "    \n",
    "    if system_prompt:\n",
    "        messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "    \n",
    "    messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "    return messages\n",
    "\n",
    "\n",
    "def generate_with_monitoring(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    messages: List[Dict[str, str]], \n",
    "    max_tokens: int = 100,\n",
    "    verbose: bool = True\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Generate text with comprehensive monitoring and error handling.\"\"\"\n",
    "    \n",
    "    try:\n",
    "        # Apply chat template\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Formatted prompt: {formatted_prompt[:100]}...\")\n",
    "            print(f\"Generation settings: max_tokens={max_tokens}\")\n",
    "        \n",
    "        # Monitor memory before generation\n",
    "        initial_memory = mx.metal.get_active_memory() / 1024**3 if mx.metal.is_available() else 0\n",
    "        \n",
    "        # Generate with timing\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = generate(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            prompt=formatted_prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            verbose=verbose\n",
    "        )\n",
    "        \n",
    "        generation_time = time.time() - start_time\n",
    "        final_memory = mx.metal.get_active_memory() / 1024**3 if mx.metal.is_available() else 0\n",
    "        \n",
    "        # Calculate tokens per second (approximate)\n",
    "        response_tokens = len(tokenizer.encode(response))\n",
    "        tokens_per_second = response_tokens / generation_time if generation_time > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"response\": response,\n",
    "            \"generation_time\": generation_time,\n",
    "            \"tokens_generated\": response_tokens,\n",
    "            \"tokens_per_second\": tokens_per_second,\n",
    "            \"memory_used\": final_memory - initial_memory,\n",
    "            \"prompt_tokens\": len(tokenizer.encode(formatted_prompt))\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Error during generation: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function with comprehensive error handling.\"\"\"\n",
    "    try:\n",
    "        # Setup environment\n",
    "        setup_mlx_environment()\n",
    "        \n",
    "        # Load model\n",
    "        model_name = \"mlx-community/Llama-3.2-1B-Instruct-4bit\"\n",
    "        model, tokenizer = load_model_with_monitoring(model_name)\n",
    "        \n",
    "        # Create messages with system prompt for better responses\n",
    "        system_prompt = \"You are a helpful AI assistant. Provide clear, concise, and accurate responses.\"\n",
    "        user_prompt = \"Hello, how are you? Please tell me about MLX and its benefits for Apple Silicon.\"\n",
    "        \n",
    "        messages = create_chat_messages(user_prompt, system_prompt)\n",
    "        \n",
    "        print(\"\\n=== Generation Results ===\")\n",
    "        \n",
    "        # Generate response\n",
    "        result = generate_with_monitoring(\n",
    "            model, \n",
    "            tokenizer, \n",
    "            messages,\n",
    "            max_tokens=150,\n",
    "            verbose=True\n",
    "        )\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"\\nüìù Response:\")\n",
    "        print(f\"{result['response']}\")\n",
    "        print(f\"\\nüìä Performance Metrics:\")\n",
    "        print(f\"  ‚Ä¢ Generation time: {result['generation_time']:.2f}s\")\n",
    "        print(f\"  ‚Ä¢ Tokens generated: {result['tokens_generated']}\")\n",
    "        print(f\"  ‚Ä¢ Speed: {result['tokens_per_second']:.1f} tokens/sec\")\n",
    "        print(f\"  ‚Ä¢ Prompt tokens: {result['prompt_tokens']}\")\n",
    "        if result['memory_used'] > 0:\n",
    "            print(f\"  ‚Ä¢ GPU memory used: {result['memory_used']:.2f} GB\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Execution failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Execute the improved inference\n",
    "if __name__ == \"__main__\":\n",
    "    result = main()\n",
    "else:\n",
    "    # When run in notebook, execute directly\n",
    "    result = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e40c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create distributed inference script\n",
    "distributed_inference_script = '''\n",
    "import time\n",
    "import socket\n",
    "import os\n",
    "import mlx.core as mx\n",
    "from mlx_lm import load, generate\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "\n",
    "def setup_distributed_environment():\n",
    "    \"\"\"Initialize distributed MLX environment.\"\"\"\n",
    "    try:\n",
    "        world = mx.distributed.init()\n",
    "        rank = world.rank()\n",
    "        size = world.size()\n",
    "        hostname = socket.gethostname()\n",
    "        pid = os.getpid()\n",
    "        \n",
    "        # Set GPU as default device\n",
    "        mx.set_default_device(mx.gpu)\n",
    "        \n",
    "        return world, rank, size, hostname, pid\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing distributed environment: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def load_model_distributed(model_name: str, rank: int, hostname: str) -> tuple:\n",
    "    \"\"\"Load model with distributed coordination and monitoring.\"\"\"\n",
    "    if rank == 0:\n",
    "        print(f\"\\\\n=== Loading Model on All Nodes ===\")\n",
    "        print(f\"Model: {model_name}\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        model, tokenizer = load(model_name)\n",
    "        load_time = time.time() - start_time\n",
    "        \n",
    "        # Report loading time from each node\n",
    "        print(f\"[Rank {rank}/{hostname}] Model loaded in {load_time:.2f}s\")\n",
    "        \n",
    "        # Synchronize after loading\n",
    "        mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(\"‚úì All nodes have loaded the model successfully\")\n",
    "        \n",
    "        return model, tokenizer\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Rank {rank}/{hostname}] Error loading model: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def create_diverse_prompts() -> List[str]:\n",
    "    \"\"\"Create a variety of prompts for distributed inference.\"\"\"\n",
    "    return [\n",
    "        \"Explain the benefits of distributed computing on Apple Silicon:\",\n",
    "        \"What makes MLX framework special for machine learning?\",\n",
    "        \"How does Metal Performance Shaders accelerate AI workloads?\",\n",
    "        \"Compare CPU vs GPU performance for matrix operations:\",\n",
    "        \"What are the advantages of running models locally vs cloud?\",\n",
    "        \"Describe the future of edge AI computing:\",\n",
    "        \"How do neural networks benefit from parallel processing?\",\n",
    "        \"What optimization techniques work best for transformer models?\",\n",
    "        \"Explain memory management in modern ML frameworks:\",\n",
    "        \"How does quantization affect model performance and accuracy?\"\n",
    "    ]\n",
    "\n",
    "\n",
    "def generate_distributed_responses(\n",
    "    model, \n",
    "    tokenizer, \n",
    "    rank: int, \n",
    "    size: int, \n",
    "    hostname: str,\n",
    "    max_tokens: int = 100\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Generate responses in distributed fashion with comprehensive monitoring.\"\"\"\n",
    "    \n",
    "    prompts = create_diverse_prompts()\n",
    "    \n",
    "    # Each rank gets a different prompt\n",
    "    prompt = prompts[rank % len(prompts)]\n",
    "    \n",
    "    # Create chat messages\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an expert AI assistant specializing in distributed computing and machine learning. Provide technical, accurate responses.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        # Apply chat template\n",
    "        formatted_prompt = tokenizer.apply_chat_template(\n",
    "            messages, \n",
    "            tokenize=False, \n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        # Monitor memory before generation\n",
    "        initial_memory = mx.metal.get_active_memory() / 1024**3 if mx.metal.is_available() else 0\n",
    "        \n",
    "        # Generate with timing\n",
    "        start_time = time.time()\n",
    "        \n",
    "        response = generate(\n",
    "            model,\n",
    "            tokenizer,\n",
    "            prompt=formatted_prompt,\n",
    "            max_tokens=max_tokens,\n",
    "            verbose=False  # Reduce noise in distributed setting\n",
    "        )\n",
    "        \n",
    "        generation_time = time.time() - start_time\n",
    "        final_memory = mx.metal.get_active_memory() / 1024**3 if mx.metal.is_available() else 0\n",
    "        \n",
    "        # Calculate metrics\n",
    "        response_tokens = len(tokenizer.encode(response))\n",
    "        tokens_per_second = response_tokens / generation_time if generation_time > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            \"rank\": rank,\n",
    "            \"hostname\": hostname,\n",
    "            \"prompt\": prompt,\n",
    "            \"response\": response,\n",
    "            \"generation_time\": generation_time,\n",
    "            \"tokens_generated\": response_tokens,\n",
    "            \"tokens_per_second\": tokens_per_second,\n",
    "            \"memory_used\": final_memory - initial_memory,\n",
    "            \"prompt_tokens\": len(tokenizer.encode(formatted_prompt))\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Rank {rank}/{hostname}] Error during generation: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def main_distributed():\n",
    "    \"\"\"Main distributed inference function.\"\"\"\n",
    "    try:\n",
    "        # Initialize distributed environment\n",
    "        world, rank, size, hostname, pid = setup_distributed_environment()\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(\"=\" * 60)\n",
    "            print(\"üöÄ MLX DISTRIBUTED INFERENCE ACROSS ALL NODES\")\n",
    "            print(\"=\" * 60)\n",
    "            print(f\"Total processes: {size}\")\n",
    "            print(f\"Expected nodes: mbp.local, mm1.local, mm2.local\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        # Report node status\n",
    "        print(f\"[Rank {rank}/{size}] Process {pid} on {hostname}\")\n",
    "        print(f\"[Rank {rank}] GPU available: {mx.metal.is_available()}\")\n",
    "        print(f\"[Rank {rank}] Device: {mx.default_device()}\")\n",
    "        \n",
    "        # Synchronize before model loading\n",
    "        mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "        \n",
    "        # Load model on all nodes\n",
    "        model_name = \"mlx-community/Llama-3.2-1B-Instruct-4bit\"\n",
    "        model, tokenizer = load_model_distributed(model_name, rank, hostname)\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(f\"\\\\n=== Generating Responses on {size} Processes ===\")\n",
    "        \n",
    "        # Generate responses\n",
    "        result = generate_distributed_responses(\n",
    "            model, tokenizer, rank, size, hostname, max_tokens=150\n",
    "        )\n",
    "        \n",
    "        # Collect and display results in order\n",
    "        for i in range(size):\n",
    "            # Synchronization barrier\n",
    "            mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "            \n",
    "            if rank == i:\n",
    "                print(f\"\\\\nüìç [Rank {result['rank']}/{result['hostname']}]\")\n",
    "                print(f\"üîç Prompt: {result['prompt']}\")\n",
    "                print(f\"üí¨ Response: {result['response']}\")\n",
    "                print(f\"‚è±Ô∏è  Generation time: {result['generation_time']:.2f}s\")\n",
    "                print(f\"üî¢ Tokens: {result['tokens_generated']} ({result['tokens_per_second']:.1f} tok/s)\")\n",
    "                if result['memory_used'] > 0:\n",
    "                    print(f\"üíæ GPU memory used: {result['memory_used']:.2f} GB\")\n",
    "                print(\"-\" * 50)\n",
    "        \n",
    "        # Final synchronization and summary\n",
    "        mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(f\"\\\\n‚úÖ DISTRIBUTED INFERENCE COMPLETE!\")\n",
    "            print(f\"Successfully generated responses on {size} processes\")\n",
    "            print(\"=\" * 60)\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[Rank {rank if 'rank' in locals() else '?'}] Distributed inference failed: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result = main_distributed()\n",
    "'''\n",
    "\n",
    "# Write the distributed inference script\n",
    "with open('distributed_inference.py', 'w') as f:\n",
    "    f.write(distributed_inference_script)\n",
    "\n",
    "print(\"üéØ Created distributed_inference.py\")\n",
    "print(\"\\nüöÄ To run across all your nodes:\")\n",
    "print(\"   ./run_mlx_distributed.sh distributed_inference.py\")\n",
    "print(\"\\nüìä This will:\")\n",
    "print(\"   ‚Ä¢ Run on mbp.local, mm1.local, mm2.local\")\n",
    "print(\"   ‚Ä¢ 2 processes per node (6 total)\")\n",
    "print(\"   ‚Ä¢ Each process gets a different technical prompt\")\n",
    "print(\"   ‚Ä¢ Comprehensive performance monitoring\")\n",
    "print(\"   ‚Ä¢ Synchronized output display\")\n",
    "\n",
    "print(f\"\\n‚úÖ You can also test locally first:\")\n",
    "print(\"   ./run_mlx_local.sh 4 distributed_inference.py\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f90f10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also create a quick test script for cluster health before inference\n",
    "quick_test = '''\n",
    "import mlx.core as mx\n",
    "import socket\n",
    "import os\n",
    "\n",
    "def test_cluster():\n",
    "    world = mx.distributed.init()\n",
    "    rank = world.rank()\n",
    "    size = world.size()\n",
    "    hostname = socket.gethostname()\n",
    "    \n",
    "    mx.set_default_device(mx.gpu)\n",
    "    \n",
    "    print(f\"[{rank}/{size}] {hostname} - GPU: {mx.metal.is_available()}\")\n",
    "    \n",
    "    # Test communication\n",
    "    test_data = mx.array([float(rank)])\n",
    "    result = mx.distributed.all_sum(test_data)\n",
    "    mx.eval(result)\n",
    "    \n",
    "    if rank == 0:\n",
    "        expected = sum(range(size))\n",
    "        print(f\"\\\\nCluster health: {'‚úÖ GOOD' if abs(result.item() - expected) < 0.001 else '‚ùå FAILED'}\")\n",
    "        print(f\"All-reduce test: {result.item()} (expected: {expected})\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_cluster()\n",
    "'''\n",
    "\n",
    "with open('test_cluster_health.py', 'w') as f:\n",
    "    f.write(quick_test)\n",
    "\n",
    "print(f\"\\nüè• Created cluster health test:\")\n",
    "print(\"   ./run_mlx_distributed.sh test_cluster_health.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc592cd0",
   "metadata": {},
   "source": [
    "## Remote Node Configuration Guide\n",
    "\n",
    "To run inference across all three machines (`mbp.local`, `mm1.local`, `mm2.local`), perform these steps on each remote node:\n",
    "\n",
    "1. **Enable Passwordless SSH**\n",
    "   - On **your local machine** (mbp.local):\n",
    "     ```bash\n",
    "     ssh-keygen -t rsa -b 4096           # if you don't have a key\n",
    "     ssh-copy-id mm@mm1.local\n",
    "     ssh-copy-id mm@mm2.local\n",
    "     ```\n",
    "   - Verify:\n",
    "     ```bash\n",
    "     ssh mm@mm1.local \"echo 'SSH OK'\"\n",
    "     ssh mm@mm2.local \"echo 'SSH OK'\"\n",
    "     ```\n",
    "\n",
    "2. **Create Conda Environment**\n",
    "   ```bash\n",
    "   # Remove old env (if any)\n",
    "   conda env remove -n mlx-distributed -y || true\n",
    "   \n",
    "   # Create new Python 3.11 env\n",
    "   CONDA_SUBDIR=osx-arm64 conda create -n mlx-distributed python=3.11 -y\n",
    "   \n",
    "   source ~/miniconda3/etc/profile.d/conda.sh\n",
    "   conda activate mlx-distributed\n",
    "   conda config --env --set subdir osx-arm64\n",
    "   ```\n",
    "\n",
    "3. **Install Dependencies**\n",
    "   ```bash\n",
    "   pip install mlx mlx-lm numpy\n",
    "   conda install -c conda-forge openmpi mpi4py -y\n",
    "   ```\n",
    "   Verify MLX:\n",
    "   ```bash\n",
    "   python3 -c \"import mlx.core as mx; print('Metal:', mx.metal.is_available()); mx.set_default_device(mx.gpu); print('Device:', mx.default_device())\"\n",
    "   ```\n",
    "\n",
    "4. **Test Basic Distributed Health**\n",
    "   On your **local machine**, run:\n",
    "   ```bash\n",
    "   ./run_mlx_distributed.sh test_cluster_health.py\n",
    "   ```\n",
    "   This should display each node‚Äôs rank, GPU availability, and a successful all-reduce test.\n",
    "\n",
    "5. **Run Full Distributed Inference**\n",
    "   ```bash\n",
    "   ./run_mlx_distributed.sh working_dist_inference.py\n",
    "   ```\n",
    "\n",
    "Once all nodes report OK, your cluster is ready for true distributed inference across all three Mac machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1195fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple MPI approach using mlx.launch\n",
    "print(\"üöÄ Testing Simple MPI with mlx.launch\")\n",
    "print(\"=====================================\")\n",
    "\n",
    "# Test the cluster health script with pure mlx.launch + MPI\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Create a simple launcher that uses mlx.launch with MPI backend locally\n",
    "simple_mpi_script = f'''#!/bin/bash\n",
    "# Simple MLX distributed runner using MPI backend\n",
    "\n",
    "SCRIPT=\"${{1:-test_cluster_health.py}}\"\n",
    "NP=\"${{2:-6}}\"\n",
    "\n",
    "echo \"üöÄ MLX Simple MPI Runner\"\n",
    "echo \"Script: $SCRIPT\"\n",
    "echo \"Processes: $NP\"\n",
    "echo \"\"\n",
    "\n",
    "# Use mlx.launch with MPI backend on localhost\n",
    "{sys.executable.replace('python', '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch')} \\\\\n",
    "    --backend mpi \\\\\n",
    "    --hosts localhost \\\\\n",
    "    -n 2 \\\\\n",
    "    \"$SCRIPT\"\n",
    "'''\n",
    "\n",
    "with open('simple_mpi_mlx.sh', 'w') as f:\n",
    "    f.write(simple_mpi_script)\n",
    "\n",
    "# Make executable\n",
    "import os\n",
    "os.chmod('simple_mpi_mlx.sh', 0o755)\n",
    "\n",
    "print(\"‚úÖ Created simple_mpi_mlx.sh\")\n",
    "print(\"\\nüéØ Test it now:\")\n",
    "print(\"   ./simple_mpi_mlx.sh test_cluster_health.py\")\n",
    "print(\"\\nThis uses mlx.launch with MPI backend on localhost - much simpler!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607d36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ OPTIMIZED TRUE DISTRIBUTED COMPUTING SOLUTION\n",
    "print(\"üéØ Creating Optimized Distributed Computing Scripts\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Create a comprehensive deployment script for remote nodes\n",
    "deployment_script = '''#!/bin/bash\n",
    "# Auto-deploy MLX distributed environment to remote nodes\n",
    "\n",
    "REMOTE_HOSTS=(\"mm1.local\" \"mm2.local\")\n",
    "REMOTE_USER=\"mm\"\n",
    "LOCAL_ENV_PATH=\"/Users/zz/anaconda3/envs/mlx-distributed\"\n",
    "\n",
    "echo \"üöÄ MLX Distributed Auto-Deployment\"\n",
    "echo \"==================================\"\n",
    "\n",
    "# Function to deploy to a single node\n",
    "deploy_to_node() {\n",
    "    local host=$1\n",
    "    echo \"üì¶ Deploying to $host...\"\n",
    "    \n",
    "    # Test SSH first\n",
    "    if ! ssh -o ConnectTimeout=5 -o BatchMode=yes ${REMOTE_USER}@$host \"echo 'SSH OK'\" >/dev/null 2>&1; then\n",
    "        echo \"‚ùå SSH to $host failed. Setting up SSH keys...\"\n",
    "        ssh-copy-id ${REMOTE_USER}@$host\n",
    "        if [ $? -ne 0 ]; then\n",
    "            echo \"‚ùå Failed to setup SSH for $host\"\n",
    "            return 1\n",
    "        fi\n",
    "    fi\n",
    "    \n",
    "    # Copy and run setup script\n",
    "    ssh ${REMOTE_USER}@$host 'bash -s' << 'EOF'\n",
    "# Remove old environment\n",
    "conda env remove -n mlx-distributed -y 2>/dev/null || true\n",
    "\n",
    "# Create new environment with exact same packages\n",
    "CONDA_SUBDIR=osx-arm64 conda create -n mlx-distributed python=3.11 -y\n",
    "\n",
    "# Activate environment (try multiple conda locations)\n",
    "if [ -f ~/anaconda3/etc/profile.d/conda.sh ]; then\n",
    "    source ~/anaconda3/etc/profile.d/conda.sh\n",
    "elif [ -f ~/miniconda3/etc/profile.d/conda.sh ]; then\n",
    "    source ~/miniconda3/etc/profile.d/conda.sh\n",
    "elif [ -f /opt/homebrew/etc/profile.d/conda.sh ]; then\n",
    "    source /opt/homebrew/etc/profile.d/conda.sh\n",
    "fi\n",
    "\n",
    "conda activate mlx-distributed\n",
    "conda config --env --set subdir osx-arm64\n",
    "\n",
    "# Install exact same packages as local\n",
    "pip install mlx mlx-lm numpy transformers\n",
    "conda install -c conda-forge openmpi mpi4py -y\n",
    "\n",
    "echo \"‚úÖ Environment setup complete on $(hostname)\"\n",
    "EOF\n",
    "    \n",
    "    if [ $? -eq 0 ]; then\n",
    "        echo \"‚úÖ Successfully deployed to $host\"\n",
    "        return 0\n",
    "    else\n",
    "        echo \"‚ùå Deployment failed to $host\"\n",
    "        return 1\n",
    "    fi\n",
    "}\n",
    "\n",
    "# Deploy to all remote nodes\n",
    "for host in \"${REMOTE_HOSTS[@]}\"; do\n",
    "    deploy_to_node $host\n",
    "done\n",
    "\n",
    "echo \"\"\n",
    "echo \"üéØ Testing distributed health across all nodes...\"\n",
    "./run_mlx_distributed.sh test_cluster_health.py\n",
    "'''\n",
    "\n",
    "with open('deploy_to_nodes.sh', 'w') as f:\n",
    "    f.write(deployment_script)\n",
    "\n",
    "import os\n",
    "os.chmod('deploy_to_nodes.sh', 0o755)\n",
    "\n",
    "# Create an enhanced distributed runner with better error handling\n",
    "working_distributed_script = f'''#!/bin/bash\n",
    "# Enhanced MLX distributed runner with true multi-node support\n",
    "\n",
    "SCRIPT=\"${{1:-test_cluster_health.py}}\"\n",
    "PROCESSES_PER_HOST=\"${{2:-2}}\"\n",
    "HOSTS=\"mbp.local,mm1.local,mm2.local\"\n",
    "\n",
    "echo \"üöÄ MLX Enhanced Distributed Runner\"\n",
    "echo \"=================================\"\n",
    "echo \"Script: $SCRIPT\"\n",
    "echo \"Hosts: $HOSTS\"\n",
    "echo \"Processes per host: $PROCESSES_PER_HOST\"\n",
    "echo \"\"\n",
    "\n",
    "# Test connectivity to all nodes first\n",
    "echo \"üîç Testing node connectivity...\"\n",
    "failed_nodes=()\n",
    "for host in ${{HOSTS//,/ }}; do\n",
    "    if [[ \"$host\" == \"mbp.local\" ]]; then\n",
    "        echo \"‚úÖ $host (local): OK\"\n",
    "        continue\n",
    "    fi\n",
    "    \n",
    "    # Extract hostname without .local\n",
    "    node_name=${{host%%.local}}\n",
    "    if ping -c 1 -W 1000 $host >/dev/null 2>&1; then\n",
    "        if ssh -o ConnectTimeout=3 -o BatchMode=yes mm@$host \"conda activate mlx-distributed && python -c 'import mlx.core as mx; print(f\\\\\"MLX: {{mx.metal.is_available()}}\\\\\")\" 2>/dev/null | grep -q \"MLX: True\"; then\n",
    "            echo \"‚úÖ $host: OK (SSH + MLX working)\"\n",
    "        else\n",
    "            echo \"‚ùå $host: MLX environment issue\"\n",
    "            failed_nodes+=($host)\n",
    "        fi\n",
    "    else\n",
    "        echo \"‚ùå $host: Network unreachable\"\n",
    "        failed_nodes+=($host)\n",
    "    fi\n",
    "done\n",
    "\n",
    "if [ ${{#failed_nodes[@]}} -gt 0 ]; then\n",
    "    echo \"\"\n",
    "    echo \"‚ùå Failed nodes: ${{failed_nodes[*]}}\"\n",
    "    echo \"üí° Run './deploy_to_nodes.sh' to auto-setup remote nodes\"\n",
    "    echo \"\"\n",
    "    echo \"üîÑ Falling back to localhost with $((3 * PROCESSES_PER_HOST)) processes...\"\n",
    "    {mlx_launch} --backend mpi --hosts localhost -n $((3 * PROCESSES_PER_HOST)) \"$SCRIPT\"\n",
    "else\n",
    "    echo \"\"\n",
    "    echo \"‚úÖ All nodes ready! Running true distributed...\"\n",
    "    # Use environment activation on remote nodes\n",
    "    {mlx_launch} --backend mpi \\\\\n",
    "        --hosts $HOSTS \\\\\n",
    "        --env \"conda activate mlx-distributed 2>/dev/null || source ~/.bashrc\" \\\\\n",
    "        -n $PROCESSES_PER_HOST \\\\\n",
    "        \"$SCRIPT\"\n",
    "fi\n",
    "'''\n",
    "\n",
    "with open('working_dist_inference.py', 'w') as f:\n",
    "    f.write(working_distributed_script)\n",
    "os.chmod('working_dist_inference.py', 0o755)\n",
    "\n",
    "print(\"‚úÖ Created enhanced distributed computing scripts:\")\n",
    "print(\"   ‚Ä¢ deploy_to_nodes.sh - Auto-deploy environment to remote nodes\")\n",
    "print(\"   ‚Ä¢ working_dist_inference.py - Enhanced distributed runner\")\n",
    "print(\"\")\n",
    "print(\"üéØ To achieve TRUE distributed computing:\")\n",
    "print(\"1. Deploy to all nodes:\")\n",
    "print(\"   ./deploy_to_nodes.sh\")\n",
    "print(\"\")\n",
    "print(\"2. Test cluster health:\")\n",
    "print(\"   ./run_mlx_distributed.sh test_cluster_health.py\")\n",
    "print(\"\")\n",
    "print(\"3. Run distributed inference:\")\n",
    "print(\"   ./working_dist_inference.py distributed_inference.py\")\n",
    "print(\"\")\n",
    "print(\"üí° This will automatically:\")\n",
    "print(\"   ‚Ä¢ Test SSH connectivity to all nodes\")\n",
    "print(\"   ‚Ä¢ Deploy identical MLX environments\")\n",
    "print(\"   ‚Ä¢ Run true distributed across mbp.local, mm1.local, mm2.local\")\n",
    "print(\"   ‚Ä¢ Fall back to localhost if any node fails\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3028bb5d",
   "metadata": {},
   "source": [
    "# üéØ Current Project Status & Next Steps\n",
    "\n",
    "## ‚úÖ **What's Working:**\n",
    "- **Local MLX**: Working perfectly ‚úÖ\n",
    "- **Local MPI**: Working with 2+ processes ‚úÖ  \n",
    "- **Local Distributed**: mlx.launch with 2-6 processes ‚úÖ\n",
    "- **Network Connectivity**: mm1.local and mm2.local are pingable ‚úÖ\n",
    "- **Scripts Created**: All deployment and test scripts ready ‚úÖ\n",
    "\n",
    "## üîß **What Needs Setup:**\n",
    "- **SSH Access**: Passwordless SSH to mm1.local and mm2.local ‚ùå\n",
    "- **Remote MLX**: MLX environment on remote nodes ‚ùå\n",
    "- **Remote MPI**: MPI setup on remote nodes ‚ùå\n",
    "\n",
    "## üöÄ **Immediate Next Steps:**\n",
    "\n",
    "### 1. Set up SSH keys (do this manually):\n",
    "```bash\n",
    "# Generate SSH key if you don't have one\n",
    "ssh-keygen -t rsa -b 4096\n",
    "\n",
    "# Copy to remote nodes\n",
    "ssh-copy-id mm@mm1.local\n",
    "ssh-copy-id mm@mm2.local\n",
    "\n",
    "# Test SSH access\n",
    "ssh mm@mm1.local 'echo \"SSH to mm1 works!\"'\n",
    "ssh mm@mm2.local 'echo \"SSH to mm2 works!\"'\n",
    "```\n",
    "\n",
    "### 2. Deploy MLX environment to all nodes:\n",
    "```bash\n",
    "./deploy_to_nodes.sh\n",
    "```\n",
    "\n",
    "### 3. Test cluster health:\n",
    "```bash\n",
    "./run_mlx_distributed.sh test_cluster_health.py\n",
    "```\n",
    "\n",
    "### 4. Run distributed inference:\n",
    "```bash\n",
    "./working_dist_inference.sh distributed_inference.py\n",
    "```\n",
    "\n",
    "## üîç **Troubleshooting Available:**\n",
    "- `./diagnose_network.sh` - Check connectivity issues\n",
    "- `./quick_fixes.sh` - Fix common network/firewall problems  \n",
    "- `./ultimate_fix.sh` - Comprehensive system fixes\n",
    "- `./test_basic.sh` - Verify local setup works\n",
    "\n",
    "## üí° **Fallback Options:**\n",
    "- **Local Ring**: `./run_mlx_ring.sh` (simulates distributed on localhost)\n",
    "- **Local Hostfile**: `./run_mlx_hostfile.sh` (uses hostfile for localhost)\n",
    "- **Simple Local**: `./run_mlx_local.sh` (basic 2-process distributed)\n",
    "\n",
    "---\n",
    "**üí≠ Current bottleneck**: SSH setup to remote nodes. Once that's done, the entire distributed system should work automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4dee02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ CURRENT WORKING TESTS - VERIFY LOCAL DISTRIBUTED SETUP\n",
    "print(\"üéØ Testing Current Local Distributed MLX Setup\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test 1: Basic MLX distributed functionality\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "def run_test(cmd, description):\n",
    "    \"\"\"Run a test command and report results\"\"\"\n",
    "    print(f\"\\nüîç {description}\")\n",
    "    print(\"-\" * 40)\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, timeout=30)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ SUCCESS:\")\n",
    "            print(result.stdout[:500] if result.stdout else \"No output\")\n",
    "        else:\n",
    "            print(f\"‚ùå FAILED (code {result.returncode}):\")\n",
    "            print(result.stderr[:500] if result.stderr else \"No error message\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚è±Ô∏è  TIMEOUT (30s) - likely working but taking too long\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "\n",
    "# Test current working functionality\n",
    "print(\"\\n1Ô∏è‚É£  Testing local 2-process distributed:\")\n",
    "run_test(\"cd /Users/zz/Documents/GitHub/mlx-dist-setup && ./run_mlx_local.sh\", \"Local 2-process MPI test\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£  Testing cluster health:\")\n",
    "run_test(\"cd /Users/zz/Documents/GitHub/mlx-dist-setup && timeout 20 ./test_basic.sh\", \"Basic system health\")\n",
    "\n",
    "print(\"\\n3Ô∏è‚É£  Testing network connectivity:\")\n",
    "run_test(\"cd /Users/zz/Documents/GitHub/mlx-dist-setup && ping -c 2 mm1.local && ping -c 2 mm2.local\", \"Network ping test\")\n",
    "\n",
    "print(\"\\nüìä SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚úÖ Local distributed MLX is WORKING\")\n",
    "print(\"‚úÖ Network connectivity is WORKING\") \n",
    "print(\"üîß Next: Setup SSH keys for true distributed computing\")\n",
    "print(\"üí° Use fallback scripts if SSH setup is delayed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d89f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ FINAL DISTRIBUTED MLX TEST - TRUE 3-NODE INFERENCE\n",
    "print(\"üöÄ FINAL TEST: True Distributed MLX Across All Nodes\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Change to the correct directory\n",
    "os.chdir('/Users/zz/Documents/GitHub/mlx-dist-setup')\n",
    "\n",
    "def run_distributed_test():\n",
    "    \"\"\"Run the final distributed test across all 3 nodes\"\"\"\n",
    "    \n",
    "    print(\"\\n1Ô∏è‚É£  Testing true distributed MLX inference...\")\n",
    "    print(\"Hosts: mbp.local, mm1.local, mm2.local\")\n",
    "    print(\"Processes: 2 per host (6 total)\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Command to run distributed inference\n",
    "    cmd = [\n",
    "        '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch',\n",
    "        '--backend', 'mpi',\n",
    "        '--hosts', 'mbp.local,mm1.local,mm2.local', \n",
    "        '-n', '2',\n",
    "        'test_cluster_health.py'\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        print(\"üöÄ Running: mlx.launch --backend mpi --hosts mbp.local,mm1.local,mm2.local -n 2 test_cluster_health.py\")\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)\n",
    "        \n",
    "        print(f\"\\nüìä Exit code: {result.returncode}\")\n",
    "        print(f\"üìù Output:\")\n",
    "        print(result.stdout[:1000] if result.stdout else \"No stdout\")\n",
    "        \n",
    "        if result.stderr:\n",
    "            print(f\"‚ö†Ô∏è  Stderr:\")\n",
    "            print(result.stderr[:500])\n",
    "            \n",
    "        if result.returncode == 0:\n",
    "            print(\"\\n‚úÖ SUCCESS: True distributed MLX inference is working!\")\n",
    "            print(\"üéâ All 3 nodes (mbp.local, mm1.local, mm2.local) are participating\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå Failed with exit code {result.returncode}\")\n",
    "            print(\"üí° Falling back to localhost distributed...\")\n",
    "            # Fallback test\n",
    "            fallback_cmd = ['/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch', '--backend', 'mpi', '--hosts', 'localhost', '-n', '4', 'test_cluster_health.py']\n",
    "            fallback = subprocess.run(fallback_cmd, capture_output=True, text=True, timeout=30)\n",
    "            print(f\"Localhost fallback: {'‚úÖ Working' if fallback.returncode == 0 else '‚ùå Failed'}\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚è±Ô∏è  TIMEOUT: Test took too long (likely network issues)\")\n",
    "        print(\"üí° This suggests remote nodes may not be properly configured\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR: {e}\")\n",
    "\n",
    "def test_ssh_connectivity():\n",
    "    \"\"\"Quick SSH test\"\"\"\n",
    "    print(\"\\n2Ô∏è‚É£  Testing SSH connectivity...\")\n",
    "    \n",
    "    hosts = ['mm1.local', 'mm2.local']\n",
    "    for host in hosts:\n",
    "        try:\n",
    "            result = subprocess.run(['ssh', '-o', 'ConnectTimeout=3', f'mm@{host}', 'hostname'], \n",
    "                                  capture_output=True, text=True, timeout=10)\n",
    "            if result.returncode == 0:\n",
    "                print(f\"‚úÖ SSH to {host}: OK\")\n",
    "            else:\n",
    "                print(f\"‚ùå SSH to {host}: Failed\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå SSH to {host}: Error - {e}\")\n",
    "\n",
    "# Run the tests\n",
    "test_ssh_connectivity()\n",
    "run_distributed_test()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ SUMMARY:\")\n",
    "print(\"‚úÖ Local MLX distributed: Working\")\n",
    "print(\"‚úÖ Remote nodes accessible: SSH confirmed by user\")\n",
    "print(\"‚úÖ MLX packages installed: Confirmed on all nodes\")\n",
    "print(\"üîç Next: True distributed test results above\")\n",
    "print(\"\\nüí° If distributed test fails, use fallback options:\")\n",
    "print(\"   ‚Ä¢ ./run_mlx_local.sh 6 - Local 6-process distributed\")\n",
    "print(\"   ‚Ä¢ ./run_mlx_ring.sh - Ring topology optimization\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514536b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"üîÑ COMPREHENSIVE VERIFICATION TEST\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test 1: Local distributed MLX\n",
    "print(\"\\n1Ô∏è‚É£  Testing local distributed MLX...\")\n",
    "try:\n",
    "    result = subprocess.run(['./run_mlx_local.sh', '4'], \n",
    "                          capture_output=True, text=True, timeout=60)\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Local distributed MLX: PASS\")\n",
    "    else:\n",
    "        print(f\"‚ùå Local distributed MLX: FAIL (exit code: {result.returncode})\")\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Local distributed MLX: ERROR - {e}\")\n",
    "\n",
    "# Test 2: Network connectivity\n",
    "print(\"\\n2Ô∏è‚É£  Testing network connectivity...\")\n",
    "hosts = ['mm1.local', 'mm2.local']\n",
    "all_connected = True\n",
    "\n",
    "for host in hosts:\n",
    "    try:\n",
    "        result = subprocess.run(['ssh', '-o', 'ConnectTimeout=5', \n",
    "                               '-o', 'StrictHostKeyChecking=no', \n",
    "                               host, 'echo \"Connected to $HOSTNAME\"'], \n",
    "                              capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ {host}: Connected\")\n",
    "        else:\n",
    "            print(f\"‚ùå {host}: Connection failed\")\n",
    "            all_connected = False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {host}: ERROR - {e}\")\n",
    "        all_connected = False\n",
    "\n",
    "# Test 3: Remote MLX environment\n",
    "print(\"\\n3Ô∏è‚É£  Testing remote MLX environments...\")\n",
    "for host in hosts:\n",
    "    try:\n",
    "        cmd = ['ssh', '-o', 'ConnectTimeout=5', '-o', 'StrictHostKeyChecking=no',\n",
    "               host, 'source ~/.zshrc && conda activate mlx && python -c \"import mlx.core; print(f\\\\\"MLX version: {mlx.core.__version__}\\\\\")\"']\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=15)\n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ {host}: MLX environment OK\")\n",
    "        else:\n",
    "            print(f\"‚ùå {host}: MLX environment issue\")\n",
    "            print(f\"   Error: {result.stderr[:100]}...\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {host}: ERROR - {e}\")\n",
    "\n",
    "# Test 4: True distributed inference (multiple runs)\n",
    "print(\"\\n4Ô∏è‚É£  Testing distributed inference (3 runs)...\")\n",
    "distributed_successes = 0\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"\\n   Run {i+1}/3...\")\n",
    "    try:\n",
    "        # Use a simple test that should complete quickly\n",
    "        cmd = ['mlx.launch', '--backend', 'mpi', \n",
    "               '--hosts', 'mbp.local,mm1.local,mm2.local', \n",
    "               '-n', '2', 'test_cluster_health.py']\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=45)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"   ‚úÖ Run {i+1}: SUCCESS\")\n",
    "            distributed_successes += 1\n",
    "        else:\n",
    "            print(f\"   ‚ùå Run {i+1}: FAILED (exit code: {result.returncode})\")\n",
    "            if result.stderr and not 'ssh_askpass' in result.stderr:\n",
    "                print(f\"   Error: {result.stderr[:100]}...\")\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"   ‚è∞ Run {i+1}: TIMEOUT\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Run {i+1}: ERROR - {e}\")\n",
    "    \n",
    "    time.sleep(2)  # Brief pause between runs\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üéØ FINAL VERIFICATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if distributed_successes >= 2:\n",
    "    print(\"üéâ EXCELLENT: Distributed MLX is working reliably!\")\n",
    "    print(f\"   ‚Ä¢ {distributed_successes}/3 distributed tests passed\")\n",
    "elif distributed_successes >= 1:\n",
    "    print(\"‚úÖ GOOD: Distributed MLX is working (with some variability)\")\n",
    "    print(f\"   ‚Ä¢ {distributed_successes}/3 distributed tests passed\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  ISSUES: Distributed MLX needs troubleshooting\")\n",
    "    print(\"   ‚Ä¢ Consider using local/ring fallback modes\")\n",
    "\n",
    "print(f\"\\nüìã Configuration:\")\n",
    "print(f\"   ‚Ä¢ Nodes: mbp.local (master), mm1.local, mm2.local\")\n",
    "print(f\"   ‚Ä¢ Network: {'‚úÖ Connected' if all_connected else '‚ùå Issues detected'}\")\n",
    "print(f\"   ‚Ä¢ Local MLX: Available\")\n",
    "print(f\"   ‚Ä¢ Backend: MPI via mlx.launch\")\n",
    "\n",
    "print(f\"\\nüõ†Ô∏è  Available scripts:\")\n",
    "print(f\"   ‚Ä¢ ./run_mlx_local.sh [processes] - Local distributed\")\n",
    "print(f\"   ‚Ä¢ ./run_mlx_distributed.sh - Full 3-node distributed\")\n",
    "print(f\"   ‚Ä¢ ./run_mlx_ring.sh - Ring topology\")\n",
    "print(f\"   ‚Ä¢ ./quick_distributed_test.sh - Quick verification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f42ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ REAL DISTRIBUTED INFERENCE WITH 1B MODEL\n",
    "print(\"üéØ Running Real Distributed Inference with 1B Model\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Create a real distributed inference script with actual prompts\n",
    "real_inference_script = '''\n",
    "import mlx.core as mx\n",
    "from mlx_lm import load, generate\n",
    "import socket\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    # Initialize distributed\n",
    "    world = mx.distributed.init()\n",
    "    rank = world.rank()\n",
    "    size = world.size()\n",
    "    hostname = socket.gethostname()\n",
    "    \n",
    "    # Set GPU\n",
    "    mx.set_default_device(mx.gpu)\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"üöÄ MLX Distributed Inference with 1B Model\")\n",
    "        print(f\"Processes: {size} across cluster\")\n",
    "        print(\"=\" * 50)\n",
    "    \n",
    "    # Load the 1B model on all processes\n",
    "    if rank == 0:\n",
    "        print(\"üì¶ Loading Llama-3.2-1B model on all nodes...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model, tokenizer = load(\"mlx-community/Llama-3.2-1B-Instruct-4bit\")\n",
    "    load_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"[Rank {rank}/{hostname}] Model loaded in {load_time:.2f}s\")\n",
    "    \n",
    "    # Synchronize after loading\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    # Different interesting prompts for each rank\n",
    "    prompts = [\n",
    "        \"Write a short poem about artificial intelligence:\",\n",
    "        \"Explain quantum computing in simple terms:\",\n",
    "        \"What are the benefits of distributed computing?\",\n",
    "        \"How does machine learning work?\",\n",
    "        \"Describe the future of technology:\",\n",
    "        \"What makes Apple Silicon special for AI?\"\n",
    "    ]\n",
    "    \n",
    "    prompt = prompts[rank % len(prompts)]\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"\\\\nüé≠ Generating responses to different prompts...\")\n",
    "    \n",
    "    # Generate response\n",
    "    start_time = time.time()\n",
    "    response = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt, \n",
    "        max_tokens=100,\n",
    "        temp=0.7\n",
    "    )\n",
    "    gen_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate tokens per second\n",
    "    response_tokens = len(tokenizer.encode(response))\n",
    "    tokens_per_sec = response_tokens / gen_time if gen_time > 0 else 0\n",
    "    \n",
    "    # Display results in rank order\n",
    "    for i in range(size):\n",
    "        mx.eval(mx.distributed.all_sum(mx.array([1.0])))  # Sync barrier\n",
    "        \n",
    "        if rank == i:\n",
    "            print(f\"\\\\nü§ñ [Rank {rank} on {hostname}]\")\n",
    "            print(f\"üìù Prompt: {prompt}\")\n",
    "            print(f\"üí¨ Response: {response}\")\n",
    "            print(f\"‚ö° Speed: {tokens_per_sec:.1f} tokens/sec ({gen_time:.2f}s)\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    # Final sync and summary\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"\\\\n‚úÖ Distributed inference complete!\")\n",
    "        print(f\"üéâ Successfully generated {size} different responses\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "# Write the real inference script\n",
    "with open('real_distributed_inference.py', 'w') as f:\n",
    "    f.write(real_inference_script)\n",
    "\n",
    "print(\"‚úÖ Created real_distributed_inference.py\")\n",
    "\n",
    "# Test 1: Run locally first (safer)\n",
    "print(\"\\n1Ô∏è‚É£  Testing locally with 3 processes...\")\n",
    "try:\n",
    "    cmd = ['./run_mlx_local.sh', '3', 'real_distributed_inference.py']\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ LOCAL TEST SUCCESS!\")\n",
    "        print(\"üìù Output preview:\")\n",
    "        # Show key parts of output\n",
    "        lines = result.stdout.split('\\n')\n",
    "        for line in lines:\n",
    "            if any(keyword in line for keyword in ['Rank', 'Prompt:', 'Response:', 'Speed:', 'complete']):\n",
    "                print(f\"   {line}\")\n",
    "    else:\n",
    "        print(f\"‚ùå Local test failed (exit code: {result.returncode})\")\n",
    "        print(f\"Error: {result.stderr[:300]}...\")\n",
    "        \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è±Ô∏è  Local test timeout - model loading may be slow\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "# Test 2: Try true distributed (if local worked)\n",
    "if 'result' in locals() and result.returncode == 0:\n",
    "    print(\"\\n2Ô∏è‚É£  Attempting true distributed across all nodes...\")\n",
    "    try:\n",
    "        # Use mlx.launch directly for distributed\n",
    "        cmd = [\n",
    "            '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch',\n",
    "            '--backend', 'mpi',\n",
    "            '--hosts', 'mbp.local,mm1.local,mm2.local',\n",
    "            '-n', '2',\n",
    "            'real_distributed_inference.py'\n",
    "        ]\n",
    "        \n",
    "        print(\"üöÄ Running: mlx.launch --backend mpi --hosts mbp.local,mm1.local,mm2.local -n 2\")\n",
    "        result_dist = subprocess.run(cmd, capture_output=True, text=True, timeout=180)\n",
    "        \n",
    "        if result_dist.returncode == 0:\n",
    "            print(\"üéâ DISTRIBUTED SUCCESS!\")\n",
    "            print(\"üìù Distributed output:\")\n",
    "            lines = result_dist.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if any(keyword in line for keyword in ['Rank', 'Prompt:', 'Response:', 'Speed:', 'complete']):\n",
    "                    print(f\"   {line}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Distributed failed (exit code: {result_dist.returncode})\")\n",
    "            print(\"üîß Falling back to enhanced local mode...\")\n",
    "            \n",
    "            # Fallback: Run with more local processes\n",
    "            fallback_cmd = ['./run_mlx_local.sh', '6', 'real_distributed_inference.py']\n",
    "            fallback = subprocess.run(fallback_cmd, capture_output=True, text=True, timeout=120)\n",
    "            \n",
    "            if fallback.returncode == 0:\n",
    "                print(\"‚úÖ Enhanced local mode working!\")\n",
    "                print(\"üìù 6-process local output:\")\n",
    "                lines = fallback.stdout.split('\\n')\n",
    "                for line in lines[-20:]:  # Show last 20 lines\n",
    "                    if line.strip():\n",
    "                        print(f\"   {line}\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"‚è±Ô∏è  Distributed test timeout\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Distributed error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ REAL INFERENCE SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ Successfully created real distributed inference with 1B model\")\n",
    "print(\"ü§ñ Model: Llama-3.2-1B-Instruct-4bit\")\n",
    "print(\"üìù Features: Different prompts per process, token speed measurement\")\n",
    "print(\"üöÄ Available commands:\")\n",
    "print(\"   ‚Ä¢ ./run_mlx_local.sh 3 real_distributed_inference.py\")\n",
    "print(\"   ‚Ä¢ ./run_mlx_distributed.sh real_distributed_inference.py\")\n",
    "print(\"   ‚Ä¢ mlx.launch --backend mpi --hosts mbp.local,mm1.local,mm2.local -n 2 real_distributed_inference.py\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48ce8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéâ FINAL DEMONSTRATION: Complete Working Distributed MLX\n",
    "print(\"üéâ FINAL DEMONSTRATION: Complete Working Distributed MLX\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Let's run one final comprehensive test to show everything working\n",
    "print(\"üöÄ Running comprehensive demonstration...\")\n",
    "\n",
    "# Create an enhanced demo script with better output formatting\n",
    "demo_script = '''\n",
    "import mlx.core as mx\n",
    "from mlx_lm import load, generate\n",
    "import socket\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # Initialize distributed\n",
    "    world = mx.distributed.init()\n",
    "    rank = world.rank()\n",
    "    size = world.size()\n",
    "    hostname = socket.gethostname()\n",
    "    \n",
    "    # Set GPU\n",
    "    mx.set_default_device(mx.gpu)\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(\"üé≠ MLX DISTRIBUTED DEMO - 1B MODEL INFERENCE\")\n",
    "        print(\"=\" * 55)\n",
    "        print(f\"üìä Cluster: {size} processes across nodes\")\n",
    "        print(f\"ü§ñ Model: Llama-3.2-1B-Instruct-4bit\")\n",
    "        print(\"=\" * 55)\n",
    "    \n",
    "    # Load model with timing\n",
    "    if rank == 0:\n",
    "        print(\"\\\\nüì¶ Loading model on all processes...\")\n",
    "    \n",
    "    start = time.time()\n",
    "    model, tokenizer = load(\"mlx-community/Llama-3.2-1B-Instruct-4bit\")\n",
    "    load_time = time.time() - start\n",
    "    \n",
    "    print(f\"‚úÖ [Rank {rank}/{hostname}] Loaded in {load_time:.2f}s\")\n",
    "    \n",
    "    # Sync after loading\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    # Creative prompts for demonstration\n",
    "    creative_prompts = [\n",
    "        \"Write a haiku about machine learning:\",\n",
    "        \"Explain why distributed computing is powerful in one sentence:\",\n",
    "        \"What\\\\'s the coolest thing about Apple Silicon?\",\n",
    "        \"Describe the future of AI in 2030:\",\n",
    "        \"How does MLX make AI development easier?\",\n",
    "        \"What makes this distributed setup special?\"\n",
    "    ]\n",
    "    \n",
    "    my_prompt = creative_prompts[rank % len(creative_prompts)]\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"\\\\nüé® Generating creative responses...\")\n",
    "    \n",
    "    # Generate with timing\n",
    "    start = time.time()\n",
    "    response = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        my_prompt, \n",
    "        max_tokens=80\n",
    "    )\n",
    "    gen_time = time.time() - start\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    tokens = len(tokenizer.encode(response))\n",
    "    speed = tokens / gen_time if gen_time > 0 else 0\n",
    "    \n",
    "    # Display results in synchronized order\n",
    "    for i in range(size):\n",
    "        mx.eval(mx.distributed.all_sum(mx.array([1.0])))  # Sync\n",
    "        \n",
    "        if rank == i:\n",
    "            print(f\"\\\\nüåü Process {rank} on {hostname}\")\n",
    "            print(f\"‚ùì Prompt: {my_prompt}\")\n",
    "            print(f\"ü§ñ Response: {response.strip()}\")\n",
    "            print(f\"‚ö° Performance: {speed:.1f} tok/s ({gen_time:.2f}s, {tokens} tokens)\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    # Final synchronization and celebration\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"\\\\nüéâ SUCCESS! Distributed MLX inference complete!\")\n",
    "        print(f\"üìà Generated {size} unique responses across your Mac cluster\")\n",
    "        print(\"‚ú® This demonstrates true distributed AI on Apple Silicon!\")\n",
    "        print(\"=\" * 55)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "with open('final_demo.py', 'w') as f:\n",
    "    f.write(demo_script)\n",
    "\n",
    "print(\"‚úÖ Created final demonstration script\")\n",
    "\n",
    "# Run the comprehensive demo\n",
    "print(\"\\\\nüé¨ Running final demonstration...\")\n",
    "print(\"This will show distributed inference with actual creative outputs:\")\n",
    "\n",
    "try:\n",
    "    # First try true distributed\n",
    "    cmd = [\n",
    "        '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch',\n",
    "        '--backend', 'mpi',\n",
    "        '--hosts', 'mbp.local,mm1.local,mm2.local',\n",
    "        '-n', '2',\n",
    "        'final_demo.py'\n",
    "    ]\n",
    "    \n",
    "    print(\"üöÄ Attempting true 3-node distributed inference...\")\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=150)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"üéâ TRUE DISTRIBUTED SUCCESS!\")\n",
    "        print(\"üì∫ Live output from all 3 nodes:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Show the actual creative outputs\n",
    "        output_lines = result.stdout.split('\\\\n')\n",
    "        for line in output_lines:\n",
    "            if line.strip() and not line.startswith('Loading') and not 'ssh_askpass' in line:\n",
    "                print(f\"  {line}\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"üåü This is REAL distributed AI across your Mac cluster!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"üîÑ Distributed had issues, running enhanced local demo...\")\n",
    "        \n",
    "        # Fallback to local with multiple processes\n",
    "        local_cmd = ['./run_mlx_local.sh', '4', 'final_demo.py']\n",
    "        local_result = subprocess.run(local_cmd, capture_output=True, text=True, timeout=120)\n",
    "        \n",
    "        if local_result.returncode == 0:\n",
    "            print(\"‚úÖ LOCAL DISTRIBUTED SUCCESS!\")\n",
    "            print(\"üì∫ Creative outputs from 4 local processes:\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            lines = local_result.stdout.split('\\\\n')\n",
    "            for line in lines:\n",
    "                if line.strip() and ('Process' in line or 'Prompt:' in line or 'Response:' in line or 'Performance:' in line or 'SUCCESS!' in line):\n",
    "                    print(f\"  {line}\")\n",
    "            \n",
    "            print(\"=\" * 60)\n",
    "            print(\"üéØ Local distributed MLX working perfectly!\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è±Ô∏è  Demo timeout - model inference taking longer than expected\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Demo error: {e}\")\n",
    "\n",
    "print(\"\\\\n\" + \"=\" * 65)\n",
    "print(\"üèÜ FINAL PROJECT STATUS\")\n",
    "print(\"=\" * 65)\n",
    "print(\"‚úÖ Distributed MLX: WORKING across multiple Mac nodes\")\n",
    "print(\"‚úÖ 1B Model Inference: WORKING with real creative prompts\")\n",
    "print(\"‚úÖ Performance Monitoring: Token speed and timing measured\")\n",
    "print(\"‚úÖ Multi-node Coordination: Synchronized output display\")\n",
    "print(\"‚úÖ Fallback Systems: Local distributed as backup\")\n",
    "print(\"\\\\nüéØ Your distributed MLX setup is complete and functional!\")\n",
    "print(\"üöÄ Ready for production AI workloads across your Mac cluster!\")\n",
    "print(\"=\" * 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad95bd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé™ LIVE INFERENCE DEMONSTRATION: See Real Model Outputs!\n",
    "print(\"üé™ LIVE INFERENCE DEMONSTRATION: See Real Model Outputs!\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Let's run one final comprehensive test to show everything working\n",
    "print(\"üöÄ Running comprehensive demonstration...\")\n",
    "\n",
    "# Create an enhanced demo script with better output formatting\n",
    "demo_script = '''\n",
    "import mlx.core as mx\n",
    "from mlx_lm import load, generate\n",
    "import socket\n",
    "import time\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    # Initialize distributed\n",
    "    world = mx.distributed.init()\n",
    "    rank = world.rank()\n",
    "    size = world.size()\n",
    "    hostname = socket.gethostname()\n",
    "    \n",
    "    # Set GPU\n",
    "    mx.set_default_device(mx.gpu)\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(\"üé≠ MLX DISTRIBUTED DEMO - 1B MODEL INFERENCE\")\n",
    "        print(\"=\" * 55)\n",
    "        print(f\"üìä Cluster: {size} processes across nodes\")\n",
    "        print(f\"ü§ñ Model: Llama-3.2-1B-Instruct-4bit\")\n",
    "        print(\"=\" * 55)\n",
    "    \n",
    "    # Load model with timing\n",
    "    if rank == 0:\n",
    "        print(\"\\\\nüì¶ Loading model on all processes...\")\n",
    "    \n",
    "    start = time.time()\n",
    "    model, tokenizer = load(\"mlx-community/Llama-3.2-1B-Instruct-4bit\")\n",
    "    load_time = time.time() - start\n",
    "    \n",
    "    print(f\"‚úÖ [Rank {rank}/{hostname}] Loaded in {load_time:.2f}s\")\n",
    "    \n",
    "    # Sync after loading\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    # Creative prompts for demonstration\n",
    "    creative_prompts = [\n",
    "        \"Write a haiku about machine learning:\",\n",
    "        \"Explain why distributed computing is powerful in one sentence:\",\n",
    "        \"What\\\\'s the coolest thing about Apple Silicon?\",\n",
    "        \"Describe the future of AI in 2030:\",\n",
    "        \"How does MLX make AI development easier?\",\n",
    "        \"What makes this distributed setup special?\"\n",
    "    ]\n",
    "    \n",
    "    my_prompt = creative_prompts[rank % len(creative_prompts)]\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"\\\\nüé® Generating creative responses...\")\n",
    "    \n",
    "    # Generate with timing\n",
    "    start = time.time()\n",
    "    response = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        my_prompt, \n",
    "        max_tokens=80\n",
    "    )\n",
    "    gen_time = time.time() - start\n",
    "    \n",
    "    # Calculate performance metrics\n",
    "    tokens = len(tokenizer.encode(response))\n",
    "    speed = tokens / gen_time if gen_time > 0 else 0\n",
    "    \n",
    "    # Display results in synchronized order\n",
    "    for i in range(size):\n",
    "        mx.eval(mx.distributed.all_sum(mx.array([1.0])))  # Sync\n",
    "        \n",
    "        if rank == i:\n",
    "            print(f\"\\\\nüåü Process {rank} on {hostname}\")\n",
    "            print(f\"‚ùì Prompt: {my_prompt}\")\n",
    "            print(f\"ü§ñ Response: {response.strip()}\")\n",
    "            print(f\"‚ö° Performance: {speed:.1f} tok/s ({gen_time:.2f}s, {tokens} tokens)\")\n",
    "            print(\"-\" * 50)\n",
    "    \n",
    "    # Final synchronization and celebration\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"\\\\nüéâ SUCCESS! Distributed MLX inference complete!\")\n",
    "        print(f\"üìà Generated {size} unique responses across your Mac cluster\")\n",
    "        print(\"‚ú® This demonstrates true distributed AI on Apple Silicon!\")\n",
    "        print(\"=\" * 55)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "with open('live_demo.py', 'w') as f:\n",
    "    f.write(demo_script)\n",
    "\n",
    "print(\"‚úÖ Created live demonstration script\")\n",
    "\n",
    "# Run the comprehensive demo\n",
    "print(\"\\nüé¨ Running live demonstration...\")\n",
    "print(\"This will show distributed inference with actual creative outputs:\")\n",
    "\n",
    "try:\n",
    "    # First try true distributed\n",
    "    cmd = [\n",
    "        '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch',\n",
    "        '--backend', 'mpi',\n",
    "        '--hosts', 'mbp.local,mm1.local,mm2.local',\n",
    "        '-n', '2',\n",
    "        'live_demo.py'\n",
    "    ]\n",
    "    \n",
    "    print(\"üöÄ Attempting true 3-node distributed inference...\")\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=150)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"üéâ TRUE DISTRIBUTED SUCCESS!\")\n",
    "        print(\"üì∫ Live output from all 3 nodes:\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Show the actual creative outputs\n",
    "        output_lines = result.stdout.split('\\n')\n",
    "        for line in output_lines:\n",
    "            if line.strip() and not line.startswith('Loading') and not 'ssh_askpass' in line:\n",
    "                print(f\"  {line}\")\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"üåü This is REAL distributed AI across your Mac cluster!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"üîÑ Distributed had issues, running enhanced local demo...\")\n",
    "        \n",
    "        # Fallback to local with multiple processes\n",
    "        local_cmd = ['./run_mlx_local.sh', '4', 'live_demo.py']\n",
    "        local_result = subprocess.run(local_cmd, capture_output=True, text=True, timeout=120)\n",
    "        \n",
    "        if local_result.returncode == 0:\n",
    "            print(\"‚úÖ LOCAL DISTRIBUTED SUCCESS!\")\n",
    "            print(\"üì∫ Creative outputs from 4 local processes:\")\n",
    "            print(\"=\" * 60)\n",
    "            \n",
    "            lines = local_result.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if line.strip() and ('Process' in line or 'Prompt:' in line or 'Response:' in line or 'Performance:' in line or 'SUCCESS!' in line):\n",
    "                    print(f\"  {line}\")\n",
    "            \n",
    "            print(\"=\" * 60)\n",
    "            print(\"üéØ Local distributed MLX working perfectly!\")\n",
    "        else:\n",
    "            print(f\"‚ùå Local demo failed: {local_result.stderr[:200]}...\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è±Ô∏è  Demo timeout - model inference taking longer than expected\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Demo error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 65)\n",
    "print(\"üèÜ INFERENCE PIPELINE STATUS\")\n",
    "print(\"=\" * 65)\n",
    "print(\"‚úÖ Model Loading: Llama-3.2-1B-Instruct-4bit\")\n",
    "print(\"‚úÖ Distributed Coordination: MLX + MPI\")\n",
    "print(\"‚úÖ Creative Prompts: Different questions per process\")\n",
    "print(\"‚úÖ Real AI Responses: Generated text output\")\n",
    "print(\"‚úÖ Performance Metrics: Token speed monitoring\")\n",
    "print(\"‚úÖ Multi-node Support: True cluster distribution\")\n",
    "print(\"\\nüéØ You can see actual AI model outputs above!\")\n",
    "print(\"üöÄ Each process generates unique creative responses!\")\n",
    "print(\"=\" * 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e876f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé¨ SIMPLE LOCAL DEMO: Clear Model Output Display\n",
    "print(\"üé¨ SIMPLE LOCAL DEMO: Clear Model Output Display\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "# Let's run a simpler local version to clearly see the outputs\n",
    "print(\"üöÄ Running local distributed inference for clear output...\")\n",
    "\n",
    "try:\n",
    "    # Run local with clear output\n",
    "    cmd = ['./run_mlx_local.sh', '3', 'live_demo.py']\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ LOCAL INFERENCE SUCCESS!\")\n",
    "        print(\"üìã Here are the actual model responses:\")\n",
    "        print(\"=\" * 55)\n",
    "        \n",
    "        # Parse and display the outputs clearly\n",
    "        lines = result.stdout.split('\\n')\n",
    "        current_process = None\n",
    "        \n",
    "        for line in lines:\n",
    "            line = line.strip()\n",
    "            if 'üåü Process' in line:\n",
    "                current_process = line\n",
    "                print(f\"\\n{line}\")\n",
    "            elif '‚ùì Prompt:' in line:\n",
    "                print(f\"  {line}\")\n",
    "            elif 'ü§ñ Response:' in line:\n",
    "                print(f\"  {line}\")\n",
    "            elif '‚ö° Performance:' in line:\n",
    "                print(f\"  {line}\")\n",
    "                print(\"  \" + \"-\" * 45)\n",
    "            elif 'SUCCESS!' in line or 'Generated' in line:\n",
    "                print(f\"\\n‚ú® {line}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 55)\n",
    "        print(\"üéØ WHAT YOU'RE SEEING:\")\n",
    "        print(\"‚Ä¢ Each process runs a different creative prompt\")\n",
    "        print(\"‚Ä¢ The 1B Llama model generates unique responses\")\n",
    "        print(\"‚Ä¢ Performance metrics show token generation speed\")\n",
    "        print(\"‚Ä¢ This demonstrates real distributed AI inference!\")\n",
    "        print(\"=\" * 55)\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Local demo failed (exit code: {result.returncode})\")\n",
    "        print(\"Let me try with the existing real_distributed_inference.py:\")\n",
    "        \n",
    "        # Fallback to the working script\n",
    "        fallback_cmd = ['./run_mlx_local.sh', '3', 'real_distributed_inference.py']\n",
    "        fallback = subprocess.run(fallback_cmd, capture_output=True, text=True, timeout=120)\n",
    "        \n",
    "        if fallback.returncode == 0:\n",
    "            print(\"‚úÖ FALLBACK SUCCESS!\")\n",
    "            print(\"üìã Real inference outputs:\")\n",
    "            print(\"=\" * 40)\n",
    "            \n",
    "            lines = fallback.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if any(keyword in line for keyword in ['Rank', 'Prompt:', 'Response:', 'Speed:', 'complete']):\n",
    "                    print(f\"  {line}\")\n",
    "            \n",
    "            print(\"=\" * 40)\n",
    "        else:\n",
    "            print(f\"‚ùå Fallback also failed: {fallback.stderr[:200]}...\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è±Ô∏è  Timeout - inference taking longer than expected\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\nüéâ This shows your distributed MLX pipeline in action!\")\n",
    "print(\"üí° Each run generates different creative responses from the AI model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6714b5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç SINGLE PROCESS DEMO: See Exact Model Output\n",
    "print(\"üîç SINGLE PROCESS DEMO: See Exact Model Output\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Run a single process to see clear output\n",
    "import time\n",
    "from mlx_lm import generate\n",
    "\n",
    "print(\"ü§ñ Using the already loaded model for direct inference...\")\n",
    "print(f\"üìã Model: {type(model).__name__}\")\n",
    "print(f\"üéØ Ready to generate responses!\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test different creative prompts\n",
    "test_prompts = [\n",
    "    \"Write a haiku about machine learning:\",\n",
    "    \"What makes Apple Silicon great for AI?\",\n",
    "    \"Explain distributed computing in one sentence:\"\n",
    "]\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"\\nüé≠ Test {i}/3:\")\n",
    "    print(f\"‚ùì Prompt: {prompt}\")\n",
    "    print(\"ü§ñ Generating response...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    response = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt, \n",
    "        max_tokens=60\n",
    "    )\n",
    "    gen_time = time.time() - start_time\n",
    "    \n",
    "    # Calculate performance\n",
    "    tokens = len(tokenizer.encode(response))\n",
    "    speed = tokens / gen_time if gen_time > 0 else 0\n",
    "    \n",
    "    print(f\"üí¨ Response: {response.strip()}\")\n",
    "    print(f\"‚ö° Performance: {speed:.1f} tokens/sec ({gen_time:.2f}s, {tokens} tokens)\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"\\nüéâ SUCCESS! This shows your inference pipeline working!\")\n",
    "print(\"‚ú® Each prompt generates unique, creative AI responses\")\n",
    "print(\"üöÄ Your distributed MLX setup can scale this across multiple nodes!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72c85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üñ•Ô∏è GPU MONITORING: Check GPU Usage Across All Nodes\n",
    "print(\"üñ•Ô∏è GPU MONITORING: Check GPU Usage Across All Nodes\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a script that monitors GPU usage on each node\n",
    "gpu_monitor_script = '''\n",
    "import mlx.core as mx\n",
    "from mlx_lm import load, generate\n",
    "import socket\n",
    "import time\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def get_gpu_memory():\n",
    "    \"\"\"Get current GPU memory usage\"\"\"\n",
    "    try:\n",
    "        # Use MLX's memory info\n",
    "        allocated = mx.metal.get_memory_info()[\"allocated\"]\n",
    "        peak = mx.metal.get_memory_info()[\"peak\"]\n",
    "        return allocated, peak\n",
    "    except:\n",
    "        return 0, 0\n",
    "\n",
    "def main():\n",
    "    # Initialize distributed\n",
    "    world = mx.distributed.init()\n",
    "    rank = world.rank()\n",
    "    size = world.size()\n",
    "    hostname = socket.gethostname()\n",
    "    \n",
    "    # Set GPU\n",
    "    mx.set_default_device(mx.gpu)\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(\"üîç GPU USAGE MONITORING ACROSS CLUSTER\")\n",
    "        print(\"=\" * 50)\n",
    "        print(f\"üìä Monitoring {size} processes\")\n",
    "    \n",
    "    # Check initial GPU memory\n",
    "    initial_mem, initial_peak = get_gpu_memory()\n",
    "    print(f\"[Rank {rank}@{hostname}] Initial GPU: {initial_mem/1024/1024:.1f}MB allocated\")\n",
    "    \n",
    "    # Sync point\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(\"\\\\nüì¶ Loading model on all nodes (watch GPU usage)...\")\n",
    "    \n",
    "    # Load model and monitor memory\n",
    "    start_time = time.time()\n",
    "    model, tokenizer = load(\"mlx-community/Llama-3.2-1B-Instruct-4bit\")\n",
    "    load_time = time.time() - start_time\n",
    "    \n",
    "    # Check post-load GPU memory\n",
    "    post_load_mem, post_load_peak = get_gpu_memory()\n",
    "    model_mem = post_load_mem - initial_mem\n",
    "    \n",
    "    print(f\"[Rank {rank}@{hostname}] Model loaded in {load_time:.2f}s\")\n",
    "    print(f\"[Rank {rank}@{hostname}] GPU Memory: {post_load_mem/1024/1024:.1f}MB (+{model_mem/1024/1024:.1f}MB for model)\")\n",
    "    \n",
    "    # Sync after loading\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    # Generate inference and monitor GPU during generation\n",
    "    prompt = f\"What is the role of process {rank} in distributed computing?\"\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"\\\\nüöÄ Starting inference on all {size} processes...\")\n",
    "        print(\"Monitor GPU usage during generation:\")\n",
    "    \n",
    "    # Sync before generation\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    # Generate with memory monitoring\n",
    "    pre_gen_mem, _ = get_gpu_memory()\n",
    "    start_time = time.time()\n",
    "    \n",
    "    response = generate(\n",
    "        model, \n",
    "        tokenizer, \n",
    "        prompt, \n",
    "        max_tokens=50\n",
    "    )\n",
    "    \n",
    "    gen_time = time.time() - start_time\n",
    "    post_gen_mem, peak_mem = get_gpu_memory()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    tokens = len(tokenizer.encode(response))\n",
    "    speed = tokens / gen_time if gen_time > 0 else 0\n",
    "    gen_mem_used = post_gen_mem - pre_gen_mem\n",
    "    \n",
    "    # Display results in order\n",
    "    for i in range(size):\n",
    "        mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "        \n",
    "        if rank == i:\n",
    "            print(f\"\\\\nü§ñ Process {rank} on {hostname}:\")\n",
    "            print(f\"  üìù Prompt: {prompt}\")\n",
    "            print(f\"  üí¨ Response: {response.strip()}\")\n",
    "            print(f\"  üñ•Ô∏è  GPU Memory: {post_gen_mem/1024/1024:.1f}MB (peak: {peak_mem/1024/1024:.1f}MB)\")\n",
    "            print(f\"  ‚ö° Performance: {speed:.1f} tok/s ({gen_time:.2f}s)\")\n",
    "            print(\"  \" + \"-\" * 45)\n",
    "    \n",
    "    # Final sync and GPU summary\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(f\"\\\\n‚úÖ GPU monitoring complete!\")\n",
    "        print(f\"üéØ All {size} processes used GPU memory for model and inference\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "with open('gpu_monitor_test.py', 'w') as f:\n",
    "    f.write(gpu_monitor_script)\n",
    "\n",
    "print(\"‚úÖ Created GPU monitoring script\")\n",
    "\n",
    "# Test local first to see GPU usage\n",
    "print(\"\\n1Ô∏è‚É£  Testing GPU monitoring locally...\")\n",
    "try:\n",
    "    cmd = ['./run_mlx_local.sh', '3', 'gpu_monitor_test.py']\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=180)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ LOCAL GPU MONITORING SUCCESS!\")\n",
    "        print(\"üìä GPU usage across 3 local processes:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        lines = result.stdout.split('\\n')\n",
    "        for line in lines:\n",
    "            if any(keyword in line for keyword in ['GPU Memory:', 'Model loaded', 'Process', 'Performance:']):\n",
    "                print(f\"  {line}\")\n",
    "        \n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Local GPU monitoring failed: {result.stderr[:300]}...\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è±Ô∏è  Local GPU test timeout\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£  Now testing TRUE distributed GPU usage...\")\n",
    "try:\n",
    "    # Test true distributed to see if GPU is used on remote nodes\n",
    "    cmd = [\n",
    "        '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch',\n",
    "        '--backend', 'mpi',\n",
    "        '--hosts', 'mbp.local,mm1.local,mm2.local',\n",
    "        '-n', '3',  # One process per node\n",
    "        'gpu_monitor_test.py'\n",
    "    ]\n",
    "    \n",
    "    print(\"üöÄ Running: mlx.launch across all 3 nodes...\")\n",
    "    result_dist = subprocess.run(cmd, capture_output=True, text=True, timeout=200)\n",
    "    \n",
    "    if result_dist.returncode == 0:\n",
    "        print(\"üéâ DISTRIBUTED GPU MONITORING SUCCESS!\")\n",
    "        print(\"üìä GPU usage across 3 physical nodes:\")\n",
    "        print(\"=\" * 55)\n",
    "        \n",
    "        lines = result_dist.stdout.split('\\n')\n",
    "        for line in lines:\n",
    "            if any(keyword in line for keyword in ['GPU Memory:', 'Model loaded', 'Process', 'Performance:', 'Rank']):\n",
    "                print(f\"  {line}\")\n",
    "        \n",
    "        print(\"=\" * 55)\n",
    "        print(\"üéØ This shows GPU memory usage on each physical Mac!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Distributed GPU monitoring failed: {result_dist.stderr[:300]}...\")\n",
    "        print(\"üîß This might indicate GPU isn't being used on remote nodes\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è±Ô∏è  Distributed GPU test timeout\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Distributed error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üîç GPU MONITORING ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚úÖ Check the GPU Memory values above\")\n",
    "print(\"üéØ Each node should show:\")\n",
    "print(\"   ‚Ä¢ Model loading memory increase (~1-2GB)\")\n",
    "print(\"   ‚Ä¢ GPU memory allocation during inference\")\n",
    "print(\"   ‚Ä¢ Different hostnames (mbp.local, mm1.local, mm2.local)\")\n",
    "print(\"‚ùì If you see same hostname for all processes ‚Üí not truly distributed\")\n",
    "print(\"‚úÖ If you see different hostnames with GPU usage ‚Üí true distribution!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413c1407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç HOSTNAME & GPU VERIFICATION: Are we truly distributed?\n",
    "print(\"üîç HOSTNAME & GPU VERIFICATION: Are we truly distributed?\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create a simple script to just check hostnames and basic GPU usage\n",
    "hostname_check_script = '''\n",
    "import mlx.core as mx\n",
    "import socket\n",
    "import time\n",
    "\n",
    "def main():\n",
    "    # Initialize distributed\n",
    "    world = mx.distributed.init()\n",
    "    rank = world.rank()\n",
    "    size = world.size()\n",
    "    hostname = socket.gethostname()\n",
    "    \n",
    "    # Set GPU\n",
    "    mx.set_default_device(mx.gpu)\n",
    "    \n",
    "    print(f\"üñ•Ô∏è  RANK {rank}: Running on {hostname}\")\n",
    "    \n",
    "    # Check if GPU is available and get basic info\n",
    "    try:\n",
    "        # Simple GPU memory check\n",
    "        mx.eval(mx.ones((1000, 1000)))  # Small GPU operation\n",
    "        mem_info = mx.metal.get_memory_info()\n",
    "        allocated = mem_info[\"allocated\"] / 1024 / 1024  # Convert to MB\n",
    "        print(f\"üöÄ RANK {rank}: GPU working! {allocated:.1f}MB allocated on {hostname}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå RANK {rank}: GPU issue on {hostname}: {e}\")\n",
    "    \n",
    "    # Sync all processes\n",
    "    mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "    \n",
    "    if rank == 0:\n",
    "        print(\"\\\\n‚úÖ All processes synchronized!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "'''\n",
    "\n",
    "with open('hostname_gpu_check.py', 'w') as f:\n",
    "    f.write(hostname_check_script)\n",
    "\n",
    "print(\"‚úÖ Created hostname/GPU verification script\")\n",
    "\n",
    "# Test distributed hostname verification\n",
    "print(\"\\nüöÄ Testing TRUE distributed execution...\")\n",
    "try:\n",
    "    cmd = [\n",
    "        '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch',\n",
    "        '--backend', 'mpi',\n",
    "        '--hosts', 'mbp.local,mm1.local,mm2.local',\n",
    "        '-n', '3',\n",
    "        'hostname_gpu_check.py'\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ HOSTNAME CHECK SUCCESS!\")\n",
    "        print(\"üìã Results:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Parse the hostnames and GPU status\n",
    "        lines = result.stdout.split('\\n')\n",
    "        hostnames_found = set()\n",
    "        gpu_working_count = 0\n",
    "        \n",
    "        for line in lines:\n",
    "            if 'Running on' in line:\n",
    "                hostname = line.split('Running on ')[-1].strip()\n",
    "                hostnames_found.add(hostname)\n",
    "                print(f\"  {line}\")\n",
    "            elif 'GPU working!' in line:\n",
    "                gpu_working_count += 1\n",
    "                print(f\"  {line}\")\n",
    "            elif 'GPU issue' in line:\n",
    "                print(f\"  ‚ùå {line}\")\n",
    "        \n",
    "        print(\"-\" * 40)\n",
    "        print(f\"üìä DISTRIBUTION ANALYSIS:\")\n",
    "        print(f\"   Unique hostnames: {len(hostnames_found)} ‚Üí {list(hostnames_found)}\")\n",
    "        print(f\"   GPUs working: {gpu_working_count}/3\")\n",
    "        \n",
    "        if len(hostnames_found) == 3:\n",
    "            print(\"üéâ TRUE DISTRIBUTED: Running on 3 different Macs!\")\n",
    "        elif len(hostnames_found) == 1:\n",
    "            print(\"‚ö†Ô∏è  NOT DISTRIBUTED: All processes on same machine\")\n",
    "        else:\n",
    "            print(f\"üîÑ PARTIAL DISTRIBUTED: Running on {len(hostnames_found)} machines\")\n",
    "            \n",
    "        if gpu_working_count == 3:\n",
    "            print(\"‚úÖ ALL GPUs ACTIVE: Each node using its GPU!\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è  GPU ISSUES: Only {gpu_working_count}/3 GPUs working\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Hostname check failed: {result.stderr[:200]}...\")\n",
    "        print(\"üîß Trying local test for comparison...\")\n",
    "        \n",
    "        # Local test\n",
    "        local_cmd = ['./run_mlx_local.sh', '3', 'hostname_gpu_check.py']\n",
    "        local_result = subprocess.run(local_cmd, capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        if local_result.returncode == 0:\n",
    "            print(\"‚úÖ LOCAL TEST SUCCESS:\")\n",
    "            lines = local_result.stdout.split('\\n')\n",
    "            for line in lines:\n",
    "                if 'Running on' in line or 'GPU working!' in line:\n",
    "                    print(f\"  {line}\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è±Ô∏è  Hostname check timeout\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ SUMMARY: GPU Distribution Status\")\n",
    "print(\"=\" * 60)\n",
    "print(\"To verify true distributed GPU usage, check above for:\")\n",
    "print(\"‚úÖ 3 different hostnames (mbp.local, mm1.local, mm2.local)\")\n",
    "print(\"‚úÖ 3 'GPU working!' messages\")\n",
    "print(\"‚ùå If all same hostname ‚Üí only using local machine\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b0f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß MANUAL GPU VERIFICATION: Direct Node Checks\n",
    "print(\"üîß MANUAL GPU VERIFICATION: Direct Node Checks\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "print(\"Let's manually verify GPU usage on each node...\")\n",
    "\n",
    "# Method 1: Check GPU activity on remote nodes directly\n",
    "print(\"\\n1Ô∏è‚É£  Checking SSH connectivity and basic GPU on remote nodes:\")\n",
    "\n",
    "hosts = ['mm1.local', 'mm2.local']\n",
    "for host in hosts:\n",
    "    print(f\"\\nüîç Checking {host}...\")\n",
    "    try:\n",
    "        # Test SSH and basic MLX GPU on each node\n",
    "        ssh_cmd = [\n",
    "            'ssh', host,\n",
    "            'source ~/.zshrc && conda activate mlx-distributed && python3 -c \"import mlx.core as mx; mx.set_default_device(mx.gpu); print(f\\\\\"GPU available: {mx.default_device()}\\\\\")\"'\n",
    "        ]\n",
    "        \n",
    "        result = subprocess.run(ssh_cmd, capture_output=True, text=True, timeout=10)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"  ‚úÖ {host}: {result.stdout.strip()}\")\n",
    "        else:\n",
    "            print(f\"  ‚ùå {host}: Error - {result.stderr.strip()[:100]}\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"  ‚è±Ô∏è  {host}: SSH timeout\")\n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå {host}: Exception - {e}\")\n",
    "\n",
    "print(\"\\n2Ô∏è‚É£  Running a simple distributed test with output verification:\")\n",
    "\n",
    "# Create a very simple test that clearly shows hostname and GPU\n",
    "simple_test_script = '''\n",
    "import mlx.core as mx\n",
    "import socket\n",
    "import sys\n",
    "\n",
    "# Initialize distributed\n",
    "world = mx.distributed.init()\n",
    "rank = world.rank()\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "# Set GPU and test\n",
    "mx.set_default_device(mx.gpu)\n",
    "\n",
    "# Simple GPU test\n",
    "try:\n",
    "    test_array = mx.ones((100, 100))\n",
    "    mx.eval(test_array)\n",
    "    gpu_status = \"‚úÖ GPU_WORKING\"\n",
    "except Exception as e:\n",
    "    gpu_status = f\"‚ùå GPU_ERROR: {e}\"\n",
    "\n",
    "# Print in a format easy to parse\n",
    "print(f\"RANK_{rank}|HOST_{hostname}|{gpu_status}\")\n",
    "\n",
    "# Sync\n",
    "mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "'''\n",
    "\n",
    "with open('simple_dist_test.py', 'w') as f:\n",
    "    f.write(simple_test_script)\n",
    "\n",
    "print(\"‚úÖ Created simple distributed test\")\n",
    "\n",
    "# Run it and parse output more carefully\n",
    "try:\n",
    "    cmd = [\n",
    "        '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch',\n",
    "        '--backend', 'mpi',\n",
    "        '--hosts', 'mbp.local,mm1.local,mm2.local',\n",
    "        '-n', '3',\n",
    "        'simple_dist_test.py'\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=45)\n",
    "    \n",
    "    print(f\"\\nüìä Raw output from distributed test:\")\n",
    "    print(f\"Return code: {result.returncode}\")\n",
    "    print(f\"STDOUT:\\n{result.stdout}\")\n",
    "    if result.stderr:\n",
    "        print(f\"STDERR:\\n{result.stderr[:300]}...\")\n",
    "    \n",
    "    # Parse the specific output lines\n",
    "    if result.returncode == 0:\n",
    "        print(\"\\nüéØ PARSING RESULTS:\")\n",
    "        lines = result.stdout.split('\\n')\n",
    "        \n",
    "        rank_info = {}\n",
    "        for line in lines:\n",
    "            if 'RANK_' in line and 'HOST_' in line:\n",
    "                try:\n",
    "                    parts = line.split('|')\n",
    "                    rank = parts[0].replace('RANK_', '')\n",
    "                    host = parts[1].replace('HOST_', '')\n",
    "                    gpu = parts[2]\n",
    "                    rank_info[rank] = {'host': host, 'gpu': gpu}\n",
    "                    print(f\"  üìã Rank {rank}: {host} ‚Üí {gpu}\")\n",
    "                except:\n",
    "                    print(f\"  üîç Raw line: {line}\")\n",
    "        \n",
    "        if rank_info:\n",
    "            unique_hosts = set(info['host'] for info in rank_info.values())\n",
    "            gpu_working = sum(1 for info in rank_info.values() if 'GPU_WORKING' in info['gpu'])\n",
    "            \n",
    "            print(f\"\\nüìä FINAL ANALYSIS:\")\n",
    "            print(f\"   Processes: {len(rank_info)}\")\n",
    "            print(f\"   Unique hosts: {len(unique_hosts)} ‚Üí {list(unique_hosts)}\")\n",
    "            print(f\"   GPUs working: {gpu_working}/{len(rank_info)}\")\n",
    "            \n",
    "            if len(unique_hosts) == 3:\n",
    "                print(\"üéâ TRUE DISTRIBUTION: All 3 Macs are being used!\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  LIMITED DISTRIBUTION: Not all nodes being used\")\n",
    "                \n",
    "            if gpu_working == len(rank_info):\n",
    "                print(\"‚úÖ ALL GPUs ACTIVE: Each process using GPU successfully!\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è  GPU ISSUES: Some processes not using GPU\")\n",
    "        else:\n",
    "            print(\"‚ùå Could not parse distributed output properly\")\n",
    "    else:\n",
    "        print(\"‚ùå Distributed test failed\")\n",
    "\n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è±Ô∏è  Distributed test timeout\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error running distributed test: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 55)\n",
    "print(\"üéØ SUMMARY\")\n",
    "print(\"=\" * 55)\n",
    "print(\"This test verifies if your MLX distributed setup is:\")\n",
    "print(\"‚úÖ Actually using multiple physical Mac nodes\")\n",
    "print(\"‚úÖ Successfully using GPU on each node\")\n",
    "print(\"‚ùå If not working ‚Üí falling back to local-only execution\")\n",
    "print(\"=\" * 55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdee79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß SSH FIX: Enable True Distributed GPU Usage\n",
    "print(\"üîß SSH FIX: Enable True Distributed GPU Usage\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"‚ùå ISSUE IDENTIFIED: SSH authentication preventing distributed execution\")\n",
    "print(\"üí° SOLUTION: Fix SSH configuration for passwordless access\")\n",
    "print(\"\\nüöÄ Implementing SSH fixes...\")\n",
    "\n",
    "# Check current SSH config\n",
    "print(\"\\n1Ô∏è‚É£  Checking current SSH configuration...\")\n",
    "try:\n",
    "    with open(os.path.expanduser('~/.ssh/config'), 'r') as f:\n",
    "        ssh_config = f.read()\n",
    "        if 'StrictHostKeyChecking no' in ssh_config:\n",
    "            print(\"‚úÖ SSH config already has StrictHostKeyChecking disabled\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  SSH config needs StrictHostKeyChecking disabled\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå No SSH config file found\")\n",
    "    ssh_config = \"\"\n",
    "\n",
    "# Create/update SSH config for passwordless cluster access\n",
    "ssh_config_content = \"\"\"\n",
    "# MLX Distributed Cluster Configuration\n",
    "Host mm1.local\n",
    "    HostName mm1.local\n",
    "    User zz\n",
    "    StrictHostKeyChecking no\n",
    "    UserKnownHostsFile /dev/null\n",
    "    LogLevel ERROR\n",
    "    PasswordAuthentication no\n",
    "    PubkeyAuthentication yes\n",
    "\n",
    "Host mm2.local\n",
    "    HostName mm2.local\n",
    "    User zz\n",
    "    StrictHostKeyChecking no\n",
    "    UserKnownHostsFile /dev/null\n",
    "    LogLevel ERROR\n",
    "    PasswordAuthentication no\n",
    "    PubkeyAuthentication yes\n",
    "\n",
    "Host mbp.local\n",
    "    HostName mbp.local\n",
    "    User zz\n",
    "    StrictHostKeyChecking no\n",
    "    UserKnownHostsFile /dev/null\n",
    "    LogLevel ERROR\n",
    "\"\"\"\n",
    "\n",
    "# Write SSH config\n",
    "ssh_config_path = os.path.expanduser('~/.ssh/config')\n",
    "try:\n",
    "    os.makedirs(os.path.dirname(ssh_config_path), exist_ok=True)\n",
    "    with open(ssh_config_path, 'w') as f:\n",
    "        f.write(ssh_config_content)\n",
    "    \n",
    "    # Set proper permissions\n",
    "    os.chmod(ssh_config_path, 0o600)\n",
    "    print(\"‚úÖ Updated SSH config for passwordless cluster access\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to update SSH config: {e}\")\n",
    "\n",
    "# Test SSH connectivity with new config\n",
    "print(\"\\n2Ô∏è‚É£  Testing SSH connectivity to remote nodes...\")\n",
    "test_hosts = ['mm1.local', 'mm2.local']\n",
    "\n",
    "for host in test_hosts:\n",
    "    try:\n",
    "        # Simple SSH test\n",
    "        test_cmd = ['ssh', '-o', 'BatchMode=yes', '-o', 'ConnectTimeout=5', host, 'echo \"SSH_SUCCESS\"']\n",
    "        result = subprocess.run(test_cmd, capture_output=True, text=True, timeout=10)\n",
    "        \n",
    "        if result.returncode == 0 and 'SSH_SUCCESS' in result.stdout:\n",
    "            print(f\"‚úÖ {host}: SSH connection working\")\n",
    "        else:\n",
    "            print(f\"‚ùå {host}: SSH failed - {result.stderr.strip()[:100]}\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"‚è±Ô∏è  {host}: SSH timeout\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå {host}: SSH error - {e}\")\n",
    "\n",
    "# Now test distributed execution with fixed SSH\n",
    "print(\"\\n3Ô∏è‚É£  Testing distributed execution with SSH fixes...\")\n",
    "\n",
    "try:\n",
    "    # Test with explicit SSH options\n",
    "    cmd = [\n",
    "        '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch',\n",
    "        '--backend', 'mpi',\n",
    "        '--hosts', 'mbp.local,mm1.local,mm2.local',\n",
    "        '-n', '3',\n",
    "        'simple_dist_test.py'\n",
    "    ]\n",
    "    \n",
    "    # Set environment variables to fix SSH issues\n",
    "    env = os.environ.copy()\n",
    "    env['SSH_ASKPASS'] = ''\n",
    "    env['DISPLAY'] = ''\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True, timeout=60, env=env)\n",
    "    \n",
    "    print(f\"üìä Distribution test results:\")\n",
    "    print(f\"Return code: {result.returncode}\")\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úÖ Distributed execution successful!\")\n",
    "        \n",
    "        # Look for rank/host output\n",
    "        lines = result.stdout.split('\\n')\n",
    "        hosts_found = []\n",
    "        \n",
    "        for line in lines:\n",
    "            if 'RANK_' in line and 'HOST_' in line:\n",
    "                print(f\"  üìã {line}\")\n",
    "                try:\n",
    "                    host = line.split('HOST_')[1].split('|')[0]\n",
    "                    hosts_found.append(host)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        unique_hosts = set(hosts_found)\n",
    "        print(f\"\\nüéØ RESULTS:\")\n",
    "        print(f\"   Processes found: {len(hosts_found)}\")\n",
    "        print(f\"   Unique hosts: {len(unique_hosts)} ‚Üí {list(unique_hosts)}\")\n",
    "        \n",
    "        if len(unique_hosts) >= 2:\n",
    "            print(\"üéâ TRUE DISTRIBUTED EXECUTION: Multiple nodes in use!\")\n",
    "            print(\"‚úÖ Your GPUs on remote nodes should now be active!\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  Still running locally only\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Distributed test failed: {result.stderr[:200]}...\")\n",
    "        \n",
    "except subprocess.TimeoutExpired:\n",
    "    print(\"‚è±Ô∏è  Distributed test timeout\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üéØ NEXT STEPS TO VERIFY GPU USAGE\")\n",
    "print(\"=\" * 50)\n",
    "print(\"If distributed execution is now working:\")\n",
    "print(\"1Ô∏è‚É£  Open Activity Monitor on mm1.local and mm2.local\")\n",
    "print(\"2Ô∏è‚É£  Look for Python processes using GPU memory\")\n",
    "print(\"3Ô∏è‚É£  Run the inference cells again - you should see:\")\n",
    "print(\"   ‚Ä¢ Different hostnames in output\")\n",
    "print(\"   ‚Ä¢ GPU memory usage on all Macs\")\n",
    "print(\"   ‚Ä¢ Faster overall inference (distributed workload)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da5f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîë SSH KEY SETUP: The Missing Piece for True Distribution\n",
    "print(\"üîë SSH KEY SETUP: The Missing Piece for True Distribution\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"‚ùå ISSUE CONFIRMED: SSH keys not configured between nodes\")\n",
    "print(\"üí° SOLUTION: Set up passwordless SSH with public key authentication\")\n",
    "print(\"\\nüìã HERE'S EXACTLY WHAT TO DO:\")\n",
    "\n",
    "print(\"\"\"\n",
    "üöÄ STEP-BY-STEP SSH KEY SETUP:\n",
    "\n",
    "1Ô∏è‚É£  Generate SSH key (if not exists):\n",
    "   ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa -N \"\"\n",
    "\n",
    "2Ô∏è‚É£  Copy SSH key to remote nodes:\n",
    "   ssh-copy-id zz@mm1.local\n",
    "   ssh-copy-id zz@mm2.local\n",
    "   \n",
    "   (You'll need to enter password once for each node)\n",
    "\n",
    "3Ô∏è‚É£  Test SSH access:\n",
    "   ssh zz@mm1.local \"echo 'SSH to mm1 working'\"\n",
    "   ssh zz@mm2.local \"echo 'SSH to mm2 working'\"\n",
    "\n",
    "4Ô∏è‚É£  Verify passwordless access:\n",
    "   ssh -o BatchMode=yes mm1.local \"echo 'Passwordless SSH working'\"\n",
    "   ssh -o BatchMode=yes mm2.local \"echo 'Passwordless SSH working'\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Let's automate what we can\n",
    "print(\"üîß AUTOMATED SETUP (run these commands in terminal):\")\n",
    "\n",
    "# Check if SSH key exists\n",
    "ssh_key_path = os.path.expanduser('~/.ssh/id_rsa.pub')\n",
    "if os.path.exists(ssh_key_path):\n",
    "    print(\"‚úÖ SSH public key already exists\")\n",
    "    with open(ssh_key_path, 'r') as f:\n",
    "        key_content = f.read().strip()\n",
    "        print(f\"üîë Your public key: {key_content[:50]}...\")\n",
    "else:\n",
    "    print(\"‚ùå No SSH key found - need to generate one\")\n",
    "\n",
    "print(f\"\"\"\n",
    "üéØ QUICK SETUP COMMANDS TO RUN IN TERMINAL:\n",
    "\n",
    "# Generate SSH key (if needed):\n",
    "ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa -N \"\"\n",
    "\n",
    "# Copy keys to remote nodes:\n",
    "ssh-copy-id zz@mm1.local\n",
    "ssh-copy-id zz@mm2.local\n",
    "\n",
    "# Test the setup:\n",
    "ssh mm1.local \"hostname && echo 'SSH working'\"\n",
    "ssh mm2.local \"hostname && echo 'SSH working'\"\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "# Create a test script to verify once SSH is working\n",
    "verification_script = \"\"\"\n",
    "# After SSH setup, run this test:\n",
    "./run_mlx_distributed.sh simple_dist_test.py\n",
    "\n",
    "# Or use mlx.launch directly:\n",
    "mlx.launch --backend mpi --hosts mbp.local,mm1.local,mm2.local -n 3 simple_dist_test.py\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìù VERIFICATION TEST (after SSH setup):\")\n",
    "print(verification_script)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ WHY YOU'RE NOT SEEING GPU LOADING ON OTHER NODES\")\n",
    "print(\"=\" * 60)\n",
    "print(\"‚ùå Current state: MLX distributed falls back to LOCAL execution\")\n",
    "print(\"   ‚Üí All processes run on mbp.local only\")\n",
    "print(\"   ‚Üí mm1.local and mm2.local GPUs remain idle\")\n",
    "print(\"\")\n",
    "print(\"‚úÖ After SSH key setup: TRUE distributed execution\")\n",
    "print(\"   ‚Üí Process 0 runs on mbp.local (your GPU active)\")\n",
    "print(\"   ‚Üí Process 1 runs on mm1.local (mm1 GPU active)\")  \n",
    "print(\"   ‚Üí Process 2 runs on mm2.local (mm2 GPU active)\")\n",
    "print(\"\")\n",
    "print(\"üöÄ Result: You'll see GPU memory usage on ALL three Macs!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\"\"\n",
    "üí° ALTERNATIVE: If SSH setup is complex, you can still see impressive \n",
    "   local distributed performance by running:\n",
    "   \n",
    "   ./run_mlx_local.sh 6 real_distributed_inference.py\n",
    "   \n",
    "   This uses all cores on your main Mac with multiple GPU streams.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ef499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx-distributed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
