{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb8b7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Use the magic command without code block formatting\n",
    "# %pip install mlx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e2e5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec mlx-distributed in /Users/zz/Library/Jupyter/kernels/mlx-distributed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "python -m ipykernel install --user --name mlx-distributed --display-name \"MLX Distributed (arm64)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2f742fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/zz/anaconda3/envs/mlx-distributed\n",
      "\n",
      "  added / updated specs:\n",
      "    - python=3.11\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2025.2.25  |       hca03da5_0         131 KB\n",
      "    openssl-3.0.16             |       h02f6b3c_0         4.3 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         4.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  bzip2              pkgs/main/osx-arm64::bzip2-1.0.8-h80987f9_6 \n",
      "  ca-certificates    pkgs/main/osx-arm64::ca-certificates-2025.2.25-hca03da5_0 \n",
      "  expat              pkgs/main/osx-arm64::expat-2.7.1-h313beb8_0 \n",
      "  libcxx             pkgs/main/osx-arm64::libcxx-17.0.6-he5c5206_4 \n",
      "  libffi             pkgs/main/osx-arm64::libffi-3.4.4-hca03da5_1 \n",
      "  ncurses            pkgs/main/osx-arm64::ncurses-6.4-h313beb8_0 \n",
      "  openssl            pkgs/main/osx-arm64::openssl-3.0.16-h02f6b3c_0 \n",
      "  pip                pkgs/main/noarch::pip-25.1-pyhc872135_2 \n",
      "  python             pkgs/main/osx-arm64::python-3.11.13-h19e8193_0 \n",
      "  readline           pkgs/main/osx-arm64::readline-8.2-h1a28f6b_0 \n",
      "  setuptools         pkgs/main/osx-arm64::setuptools-78.1.1-py311hca03da5_0 \n",
      "  sqlite             pkgs/main/osx-arm64::sqlite-3.45.3-h80987f9_0 \n",
      "  tk                 pkgs/main/osx-arm64::tk-8.6.14-h6ba3021_1 \n",
      "  tzdata             pkgs/main/noarch::tzdata-2025b-h04d1e81_0 \n",
      "  wheel              pkgs/main/osx-arm64::wheel-0.45.1-py311hca03da5_0 \n",
      "  xz                 pkgs/main/osx-arm64::xz-5.6.4-h80987f9_1 \n",
      "  zlib               pkgs/main/osx-arm64::zlib-1.2.13-h18a0788_1 \n",
      "\n",
      "\n",
      "\n",
      "openssl-3.0.16       | 4.3 MB    |            |   0% \n",
      "ca-certificates-2025 | 131 KB    |            |   0% \u001b[A\n",
      "openssl-3.0.16       | 4.3 MB    | 2          |   3% \u001b[A\n",
      "ca-certificates-2025 | 131 KB    | ########## | 100% \u001b[A\n",
      "                                                     \u001b[A\n",
      "                                                     \u001b[A done\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "#\n",
      "# To activate this environment, use\n",
      "#\n",
      "#     $ conda activate mlx-distributed\n",
      "#\n",
      "# To deactivate an active environment, use\n",
      "#\n",
      "#     $ conda deactivate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "CondaError: Run 'conda init' before 'conda activate'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment created successfully!\n",
      "mlx-distributed      * /Users/zz/anaconda3/envs/mlx-distributed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Remove existing environment if it exists\n",
    "conda env remove -n mlx-distributed -y 2>/dev/null || true\n",
    "\n",
    "# Create fresh environment with Python 3.11 (optimal for MLX)\n",
    "CONDA_SUBDIR=osx-arm64 conda create -n mlx-distributed python=3.11 -y\n",
    "\n",
    "# Activate and configure for ARM64\n",
    "\n",
    "conda activate mlx-distributed\n",
    "conda config --env --set subdir osx-arm64\n",
    "\n",
    "echo \"Environment created successfully!\"\n",
    "conda info --envs | grep mlx-distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d512e554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/zz/anaconda3/envs/mlx-distributed\n",
      "\n",
      "  added / updated specs:\n",
      "    - openmpi\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    openmpi-4.1.3              |       h8b79891_4           9 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:           9 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  mpi                conda-forge/osx-arm64::mpi-1.0-openmpi \n",
      "  openmpi            conda-forge/noarch::openmpi-4.1.3-h8b79891_4 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  ca-certificates    pkgs/main/osx-arm64::ca-certificates-~ --> conda-forge/noarch::ca-certificates-2025.6.15-hbd8a1cb_0 \n",
      "  openssl              pkgs/main::openssl-3.0.16-h02f6b3c_0 --> conda-forge::openssl-3.5.1-h81ee809_0 \n",
      "\n",
      "\n",
      "\n",
      " done                                                \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Channels:\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/zz/anaconda3/envs/mlx-distributed\n",
      "\n",
      "  added / updated specs:\n",
      "    - mpi4py\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    mpi4py-3.1.4               |  py311he4f2fd2_0         472 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         472 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  mpi4py             pkgs/main/osx-arm64::mpi4py-3.1.4-py311he4f2fd2_0 \n",
      "\n",
      "\n",
      "\n",
      " done                                                \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting mlx\n",
      "  Using cached mlx-0.26.2-cp311-cp311-macosx_15_0_arm64.whl.metadata (5.3 kB)\n",
      "Collecting mlx-lm\n",
      "  Using cached mlx_lm-0.25.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting numpy (from mlx-lm)\n",
      "  Using cached numpy-2.3.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Collecting transformers>=4.39.3 (from transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached transformers-4.53.0-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting protobuf (from mlx-lm)\n",
      "  Using cached protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Collecting pyyaml (from mlx-lm)\n",
      "  Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Collecting jinja2 (from mlx-lm)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting filelock (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0 (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached huggingface_hub-0.33.2-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting packaging>=20.0 (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Collecting requests (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting tqdm>=4.27 (from transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.30.0->transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface-hub<1.0,>=0.30.0->transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached typing_extensions-4.14.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting hf-xet<2.0.0,>=1.1.2 (from huggingface-hub<1.0,>=0.30.0->transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl.metadata (879 bytes)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (7.7 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->mlx-lm)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->transformers>=4.39.3->transformers[sentencepiece]>=4.39.3->mlx-lm)\n",
      "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Using cached mlx-0.26.2-cp311-cp311-macosx_15_0_arm64.whl (32.5 MB)\n",
      "Using cached mlx_lm-0.25.3-py3-none-any.whl (203 kB)\n",
      "Using cached transformers-4.53.0-py3-none-any.whl (10.8 MB)\n",
      "Using cached huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Using cached hf_xet-1.1.5-cp37-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached tokenizers-0.21.2-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached numpy-2.3.1-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
      "Using cached packaging-25.0-py3-none-any.whl (66 kB)\n",
      "Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Using cached sentencepiece-0.2.0-cp311-cp311-macosx_11_0_arm64.whl (1.2 MB)\n",
      "Using cached typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached protobuf-6.31.1-cp39-abi3-macosx_10_9_universal2.whl (425 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl (198 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Installing collected packages: sentencepiece, urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, protobuf, packaging, numpy, mlx, MarkupSafe, idna, hf-xet, fsspec, filelock, charset_normalizer, certifi, requests, jinja2, huggingface-hub, tokenizers, transformers, mlx-lm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━90m╺\u001b[0m\u001b[━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/24\u001b[0m [pyyaml]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/24\u001b[0m [numpy]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/24\u001b[0m [numpy]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/24\u001b[0m [numpy]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/24\u001b[0m [numpy]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/24\u001b[0m [numpy]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/24\u001b[0m [mlx]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/24\u001b[0m [mlx]90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/24\u001b[0m [fsspec]━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m20/24\u001b[0m [huggingface-hub]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m22/24\u001b[0m [transformers]━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m23/24\u001b[0m [mlx-lm]━━━━━━━━━━━\u001b[0m \u001b[32m24/24\u001b[0m [mlx-lm]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 certifi-2025.6.15 charset_normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 hf-xet-1.1.5 huggingface-hub-0.33.2 idna-3.10 jinja2-3.1.6 mlx-0.26.2 mlx-lm-0.25.3 numpy-2.3.1 packaging-25.0 protobuf-6.31.1 pyyaml-6.0.2 regex-2024.11.6 requests-2.32.4 safetensors-0.5.3 sentencepiece-0.2.0 tokenizers-0.21.2 tqdm-4.67.1 transformers-4.53.0 typing-extensions-4.14.0 urllib3-2.5.0\n",
      "Requirement already satisfied: numpy in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (2.3.1)\n",
      "Collecting jupyter\n",
      "  Using cached jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting ipykernel\n",
      "  Using cached ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting notebook (from jupyter)\n",
      "  Using cached notebook-7.4.4-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jupyter-console (from jupyter)\n",
      "  Using cached jupyter_console-6.6.3-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting nbconvert (from jupyter)\n",
      "  Using cached nbconvert-7.16.6-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting ipywidgets (from jupyter)\n",
      "  Using cached ipywidgets-8.1.7-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting jupyterlab (from jupyter)\n",
      "  Using cached jupyterlab-4.4.4-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting appnope (from ipykernel)\n",
      "  Using cached appnope-0.1.4-py2.py3-none-any.whl.metadata (908 bytes)\n",
      "Collecting comm>=0.1.1 (from ipykernel)\n",
      "  Using cached comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting debugpy>=1.6.5 (from ipykernel)\n",
      "  Using cached debugpy-1.8.14-cp311-cp311-macosx_14_0_universal2.whl.metadata (1.3 kB)\n",
      "Collecting ipython>=7.23.1 (from ipykernel)\n",
      "  Using cached ipython-9.4.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting jupyter-client>=6.1.12 (from ipykernel)\n",
      "  Using cached jupyter_client-8.6.3-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting jupyter-core!=5.0.*,>=4.12 (from ipykernel)\n",
      "  Using cached jupyter_core-5.8.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting matplotlib-inline>=0.1 (from ipykernel)\n",
      "  Using cached matplotlib_inline-0.1.7-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting nest-asyncio (from ipykernel)\n",
      "  Using cached nest_asyncio-1.6.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: packaging in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from ipykernel) (25.0)\n",
      "Collecting psutil (from ipykernel)\n",
      "  Using cached psutil-7.0.0-cp36-abi3-macosx_11_0_arm64.whl.metadata (22 kB)\n",
      "Collecting pyzmq>=24 (from ipykernel)\n",
      "  Using cached pyzmq-27.0.0-cp311-cp311-macosx_10_15_universal2.whl.metadata (6.0 kB)\n",
      "Collecting tornado>=6.1 (from ipykernel)\n",
      "  Using cached tornado-6.5.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (2.8 kB)\n",
      "Collecting traitlets>=5.4.0 (from ipykernel)\n",
      "  Using cached traitlets-5.14.3-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting decorator (from ipython>=7.23.1->ipykernel)\n",
      "  Using cached decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting ipython-pygments-lexers (from ipython>=7.23.1->ipykernel)\n",
      "  Using cached ipython_pygments_lexers-1.1.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
      "  Using cached jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting pexpect>4.3 (from ipython>=7.23.1->ipykernel)\n",
      "  Using cached pexpect-4.9.0-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting prompt_toolkit<3.1.0,>=3.0.41 (from ipython>=7.23.1->ipykernel)\n",
      "  Using cached prompt_toolkit-3.0.51-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting pygments>=2.4.0 (from ipython>=7.23.1->ipykernel)\n",
      "  Using cached pygments-2.19.2-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting stack_data (from ipython>=7.23.1->ipykernel)\n",
      "  Using cached stack_data-0.6.3-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from ipython>=7.23.1->ipykernel) (4.14.0)\n",
      "Collecting wcwidth (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=7.23.1->ipykernel)\n",
      "  Using cached wcwidth-0.2.13-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting parso<0.9.0,>=0.8.4 (from jedi>=0.16->ipython>=7.23.1->ipykernel)\n",
      "  Using cached parso-0.8.4-py2.py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting python-dateutil>=2.8.2 (from jupyter-client>=6.1.12->ipykernel)\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting platformdirs>=2.5 (from jupyter-core!=5.0.*,>=4.12->ipykernel)\n",
      "  Using cached platformdirs-4.3.8-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting ptyprocess>=0.5 (from pexpect>4.3->ipython>=7.23.1->ipykernel)\n",
      "  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->jupyter-client>=6.1.12->ipykernel)\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting widgetsnbextension~=4.0.14 (from ipywidgets->jupyter)\n",
      "  Using cached widgetsnbextension-4.0.14-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab_widgets~=3.0.15 (from ipywidgets->jupyter)\n",
      "  Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached async_lru-2.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting httpx>=0.25.0 (from jupyterlab->jupyter)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: jinja2>=3.0.3 in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from jupyterlab->jupyter) (3.1.6)\n",
      "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter)\n",
      "  Using cached jupyter_server-2.16.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter)\n",
      "  Using cached jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting notebook-shim>=0.2 (from jupyterlab->jupyter)\n",
      "  Using cached notebook_shim-0.2.4-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: setuptools>=41.1.0 in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from jupyterlab->jupyter) (78.1.1)\n",
      "Collecting anyio>=3.1.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting argon2-cffi>=21.1 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached argon2_cffi-25.1.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting jupyter-events>=0.11.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_events-0.12.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting nbformat>=5.3.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached nbformat-5.10.4-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting prometheus-client>=0.9 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached prometheus_client-0.22.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting send2trash>=1.8.2 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached Send2Trash-1.8.3-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting terminado>=0.8.3 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached terminado-0.18.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting websocket-client>=1.7 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting babel>=2.10 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached babel-2.17.0-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached json5-0.12.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting jsonschema>=4.18.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached jsonschema-4.24.0-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: requests>=2.31 in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.32.4)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (3.10)\n",
      "Collecting sniffio>=1.1 (from anyio>=3.1.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting argon2-cffi-bindings (from argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: certifi in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from httpx>=0.25.0->jupyterlab->jupyter) (2025.6.15)\n",
      "Collecting httpcore==1.* (from httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from jinja2>=3.0.3->jupyterlab->jupyter) (3.0.2)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter)\n",
      "  Using cached rpds_py-0.26.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.2 kB)\n",
      "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3 in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter) (6.0.2)\n",
      "Collecting rfc3339-validator (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting jsonpointer>1.13 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
      "Collecting webcolors>=24.6.0 (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached webcolors-24.11.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting beautifulsoup4 (from nbconvert->jupyter)\n",
      "  Using cached beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting bleach!=5.0.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached bleach-6.2.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting defusedxml (from nbconvert->jupyter)\n",
      "  Using cached defusedxml-0.7.1-py2.py3-none-any.whl.metadata (32 kB)\n",
      "Collecting jupyterlab-pygments (from nbconvert->jupyter)\n",
      "  Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting mistune<4,>=2.0.3 (from nbconvert->jupyter)\n",
      "  Using cached mistune-3.1.3-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nbclient>=0.5.0 (from nbconvert->jupyter)\n",
      "  Using cached nbclient-0.10.2-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter)\n",
      "  Using cached pandocfilters-1.5.1-py2.py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting webencodings (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting tinycss2<1.5,>=1.1.0 (from bleach[css]!=5.0.0->nbconvert->jupyter)\n",
      "  Using cached tinycss2-1.4.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting fastjsonschema>=2.15 (from nbformat>=5.3.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached fastjsonschema-2.21.1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages (from requests>=2.31->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter) (2.5.0)\n",
      "Collecting cffi>=1.0.1 (from argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (1.5 kB)\n",
      "Collecting pycparser (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi>=21.1->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->nbconvert->jupyter)\n",
      "  Using cached soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter)\n",
      "  Using cached types_python_dateutil-2.9.0.20250516-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting executing>=1.2.0 (from stack_data->ipython>=7.23.1->ipykernel)\n",
      "  Using cached executing-2.2.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Collecting asttokens>=2.1.0 (from stack_data->ipython>=7.23.1->ipykernel)\n",
      "  Using cached asttokens-3.0.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pure-eval (from stack_data->ipython>=7.23.1->ipykernel)\n",
      "  Using cached pure_eval-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Using cached jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Using cached ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
      "Using cached comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Using cached debugpy-1.8.14-cp311-cp311-macosx_14_0_universal2.whl (2.2 MB)\n",
      "Using cached ipython-9.4.0-py3-none-any.whl (611 kB)\n",
      "Using cached prompt_toolkit-3.0.51-py3-none-any.whl (387 kB)\n",
      "Using cached jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
      "Using cached parso-0.8.4-py2.py3-none-any.whl (103 kB)\n",
      "Using cached jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "Using cached jupyter_core-5.8.1-py3-none-any.whl (28 kB)\n",
      "Using cached matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Using cached pexpect-4.9.0-py2.py3-none-any.whl (63 kB)\n",
      "Using cached platformdirs-4.3.8-py3-none-any.whl (18 kB)\n",
      "Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
      "Using cached pygments-2.19.2-py3-none-any.whl (1.2 MB)\n",
      "Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "Using cached pyzmq-27.0.0-cp311-cp311-macosx_10_15_universal2.whl (1.3 MB)\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
      "Using cached tornado-6.5.1-cp39-abi3-macosx_10_9_universal2.whl (441 kB)\n",
      "Using cached traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "Using cached appnope-0.1.4-py2.py3-none-any.whl (4.3 kB)\n",
      "Using cached decorator-5.2.1-py3-none-any.whl (9.2 kB)\n",
      "Using cached ipython_pygments_lexers-1.1.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached ipywidgets-8.1.7-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.15-py3-none-any.whl (216 kB)\n",
      "Using cached widgetsnbextension-4.0.14-py3-none-any.whl (2.2 MB)\n",
      "Using cached jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached jupyterlab-4.4.4-py3-none-any.whl (12.3 MB)\n",
      "Using cached jupyter_server-2.16.0-py3-none-any.whl (386 kB)\n",
      "Using cached jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached argon2_cffi-25.1.0-py3-none-any.whl (14 kB)\n",
      "Using cached async_lru-2.0.5-py3-none-any.whl (6.1 kB)\n",
      "Using cached babel-2.17.0-py3-none-any.whl (10.2 MB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached json5-0.12.0-py3-none-any.whl (36 kB)\n",
      "Using cached jsonschema-4.24.0-py3-none-any.whl (88 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
      "Using cached jupyter_events-0.12.0-py3-none-any.whl (19 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
      "Using cached jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
      "Using cached nbconvert-7.16.6-py3-none-any.whl (258 kB)\n",
      "Using cached mistune-3.1.3-py3-none-any.whl (53 kB)\n",
      "Using cached bleach-6.2.0-py3-none-any.whl (163 kB)\n",
      "Using cached tinycss2-1.4.0-py3-none-any.whl (26 kB)\n",
      "Using cached nbclient-0.10.2-py3-none-any.whl (25 kB)\n",
      "Using cached nbformat-5.10.4-py3-none-any.whl (78 kB)\n",
      "Using cached fastjsonschema-2.21.1-py3-none-any.whl (23 kB)\n",
      "Using cached notebook_shim-0.2.4-py3-none-any.whl (13 kB)\n",
      "Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Using cached pandocfilters-1.5.1-py2.py3-none-any.whl (8.7 kB)\n",
      "Using cached prometheus_client-0.22.1-py3-none-any.whl (58 kB)\n",
      "Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached referencing-0.36.2-py3-none-any.whl (26 kB)\n",
      "Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached rpds_py-0.26.0-cp311-cp311-macosx_11_0_arm64.whl (358 kB)\n",
      "Using cached Send2Trash-1.8.3-py3-none-any.whl (18 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached terminado-0.18.1-py3-none-any.whl (14 kB)\n",
      "Using cached webcolors-24.11.1-py3-none-any.whl (14 kB)\n",
      "Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached argon2_cffi_bindings-21.2.0-cp38-abi3-macosx_10_9_universal2.whl (53 kB)\n",
      "Using cached cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl (178 kB)\n",
      "Using cached beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
      "Using cached soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)\n",
      "Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
      "Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
      "Using cached arrow-1.3.0-py3-none-any.whl (66 kB)\n",
      "Using cached types_python_dateutil-2.9.0.20250516-py3-none-any.whl (14 kB)\n",
      "Using cached jupyterlab_pygments-0.3.0-py3-none-any.whl (15 kB)\n",
      "Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)\n",
      "Using cached notebook-7.4.4-py3-none-any.whl (14.3 MB)\n",
      "Using cached psutil-7.0.0-cp36-abi3-macosx_11_0_arm64.whl (239 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Using cached asttokens-3.0.0-py3-none-any.whl (26 kB)\n",
      "Using cached executing-2.2.0-py2.py3-none-any.whl (26 kB)\n",
      "Using cached pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "Using cached uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
      "Using cached wcwidth-0.2.13-py2.py3-none-any.whl (34 kB)\n",
      "Installing collected packages: webencodings, wcwidth, pure-eval, ptyprocess, fastjsonschema, widgetsnbextension, websocket-client, webcolors, uri-template, types-python-dateutil, traitlets, tornado, tinycss2, soupsieve, sniffio, six, send2trash, rpds-py, rfc3986-validator, pyzmq, python-json-logger, pygments, pycparser, psutil, prompt_toolkit, prometheus-client, platformdirs, pexpect, parso, pandocfilters, overrides, nest-asyncio, mistune, jupyterlab_widgets, jupyterlab-pygments, jsonpointer, json5, h11, fqdn, executing, defusedxml, decorator, debugpy, bleach, babel, attrs, async-lru, asttokens, appnope, terminado, stack_data, rfc3339-validator, referencing, python-dateutil, matplotlib-inline, jupyter-core, jedi, ipython-pygments-lexers, httpcore, comm, cffi, beautifulsoup4, anyio, jupyter-server-terminals, jupyter-client, jsonschema-specifications, ipython, httpx, arrow, argon2-cffi-bindings, jsonschema, isoduration, ipywidgets, ipykernel, argon2-cffi, nbformat, jupyter-console, nbclient, jupyter-events, nbconvert, jupyter-server, notebook-shim, jupyterlab-server, jupyter-lsp, jupyterlab, notebook, jupyter\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[91m╸[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/87\u001b[0m [tornado]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/87\u001b[0m [pyzmq]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/87\u001b[0m [pygments]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/87\u001b[0m [pygments]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24/87\u001b[0m [prompt_toolkit]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/87\u001b[0m [overrides]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42/87\u001b[0m [debugpy]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42/87\u001b[0m [debugpy]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/87\u001b[0m [babel]━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44/87\u001b[0m [babel]\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m56/87\u001b[0m [jedi]\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m56/87\u001b[0m [jedi]\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m64/87\u001b[0m [jupyter-client]━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m66/87\u001b[0m [ipython]━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m73/87\u001b[0m [ipykernel]━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m80/87\u001b[0m [jupyter-server]━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m84/87\u001b[0m [jupyterlab]━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m85/87\u001b[0m [notebook]━━━━━━━━━━━\u001b[0m \u001b[32m87/87\u001b[0m [jupyter]\n",
      "\u001b[1A\u001b[2KSuccessfully installed anyio-4.9.0 appnope-0.1.4 argon2-cffi-25.1.0 argon2-cffi-bindings-21.2.0 arrow-1.3.0 asttokens-3.0.0 async-lru-2.0.5 attrs-25.3.0 babel-2.17.0 beautifulsoup4-4.13.4 bleach-6.2.0 cffi-1.17.1 comm-0.2.2 debugpy-1.8.14 decorator-5.2.1 defusedxml-0.7.1 executing-2.2.0 fastjsonschema-2.21.1 fqdn-1.5.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 ipykernel-6.29.5 ipython-9.4.0 ipython-pygments-lexers-1.1.1 ipywidgets-8.1.7 isoduration-20.11.0 jedi-0.19.2 json5-0.12.0 jsonpointer-3.0.0 jsonschema-4.24.0 jsonschema-specifications-2025.4.1 jupyter-1.1.1 jupyter-client-8.6.3 jupyter-console-6.6.3 jupyter-core-5.8.1 jupyter-events-0.12.0 jupyter-lsp-2.2.5 jupyter-server-2.16.0 jupyter-server-terminals-0.5.3 jupyterlab-4.4.4 jupyterlab-pygments-0.3.0 jupyterlab-server-2.27.3 jupyterlab_widgets-3.0.15 matplotlib-inline-0.1.7 mistune-3.1.3 nbclient-0.10.2 nbconvert-7.16.6 nbformat-5.10.4 nest-asyncio-1.6.0 notebook-7.4.4 notebook-shim-0.2.4 overrides-7.7.0 pandocfilters-1.5.1 parso-0.8.4 pexpect-4.9.0 platformdirs-4.3.8 prometheus-client-0.22.1 prompt_toolkit-3.0.51 psutil-7.0.0 ptyprocess-0.7.0 pure-eval-0.2.3 pycparser-2.22 pygments-2.19.2 python-dateutil-2.9.0.post0 python-json-logger-3.3.0 pyzmq-27.0.0 referencing-0.36.2 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rpds-py-0.26.0 send2trash-1.8.3 six-1.17.0 sniffio-1.3.1 soupsieve-2.7 stack_data-0.6.3 terminado-0.18.1 tinycss2-1.4.0 tornado-6.5.1 traitlets-5.14.3 types-python-dateutil-2.9.0.20250516 uri-template-1.3.0 wcwidth-0.2.13 webcolors-24.11.1 webencodings-0.5.1 websocket-client-1.8.0 widgetsnbextension-4.0.14\n",
      "Installed kernelspec mlx-distributed in /Users/zz/Library/Jupyter/kernels/mlx-distributed\n",
      "Installation complete!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Activate environment\n",
    "source ~/anaconda3/etc/profile.d/conda.sh\n",
    "conda activate mlx-distributed\n",
    "\n",
    "# Install OpenMPI via conda (not homebrew!)\n",
    "conda install -c conda-forge openmpi -y\n",
    "\n",
    "# Install mpi4py\n",
    "conda install -c conda-forge mpi4py -y\n",
    "\n",
    "# Install MLX and MLX-LM\n",
    "pip install mlx mlx-lm\n",
    "\n",
    "# Install additional utilities\n",
    "pip install numpy jupyter ipykernel\n",
    "\n",
    "# Add kernel to Jupyter\n",
    "python -m ipykernel install --user --name mlx-distributed --display-name \"MLX Distributed\"\n",
    "\n",
    "echo \"Installation complete!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3474418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== System Information ===\n",
      "Python: 3.11.13 (main, Jun  5 2025, 08:21:08) [Clang 14.0.6 ]\n",
      "Platform: macOS-15.5-arm64-arm-64bit\n",
      "Architecture: arm64\n",
      "Python executable: /Users/zz/anaconda3/envs/mlx-distributed/bin/python\n",
      "\n",
      "=== MLX Installation ===\n",
      "✗ MLX error: module 'mlx' has no attribute '__version__'\n",
      "\n",
      "=== MPI Installation ===\n",
      "✗ MPI error: dlopen(/Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/MPI.cpython-311-darwin.so, 0x0002): Library not loaded: @rpath/libmpi.40.dylib\n",
      "  Referenced from: <A853210E-CFB8-34D9-8C29-289BC747DD98> /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/MPI.cpython-311-darwin.so\n",
      "  Reason: tried: '/Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/../../../libmpi.40.dylib' (no such file), '/Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/../../../libmpi.40.dylib' (no such file), '/Users/zz/anaconda3/envs/mlx-distributed/bin/../lib/libmpi.40.dylib' (no such file), '/Users/zz/anaconda3/envs/mlx-distributed/bin/../lib/libmpi.40.dylib' (no such file), '/usr/local/lib/libmpi.40.dylib' (no such file), '/usr/lib/libmpi.40.dylib' (no such file, not in dyld cache)\n",
      "\n",
      "=== MLX-LM Installation ===\n",
      "✓ mlx_lm installed successfully\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import subprocess\n",
    "\n",
    "print(\"=== System Information ===\")\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")\n",
    "print(f\"Python executable: {sys.executable}\")\n",
    "print()\n",
    "\n",
    "print(\"=== MLX Installation ===\")\n",
    "try:\n",
    "    import mlx\n",
    "    import mlx.core as mx\n",
    "    print(f\"✓ MLX version: {mlx.__version__}\")\n",
    "    print(f\"✓ Metal available: {mx.metal.is_available()}\")\n",
    "    print(f\"✓ Default device: {mx.default_device()}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ MLX error: {e}\")\n",
    "print()\n",
    "\n",
    "print(\"=== MPI Installation ===\")\n",
    "try:\n",
    "    from mpi4py import MPI\n",
    "    print(f\"✓ mpi4py version: {MPI.Get_version()}\")\n",
    "    print(f\"✓ MPI vendor: {MPI.get_vendor()}\")\n",
    "    \n",
    "    # Check MPI executable\n",
    "    result = subprocess.run(['which', 'mpirun'], capture_output=True, text=True)\n",
    "    print(f\"✓ mpirun location: {result.stdout.strip()}\")\n",
    "    \n",
    "    # Check MPI version - fix for f-string issue\n",
    "    result = subprocess.run(['mpirun', '--version'], capture_output=True, text=True)\n",
    "    first_line = result.stdout.strip().split('\\n')[0]  # Move split outside f-string\n",
    "    print(f\"✓ MPI version: {first_line}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ MPI error: {e}\")\n",
    "print()\n",
    "\n",
    "print(\"=== MLX-LM Installation ===\")\n",
    "try:\n",
    "    import mlx_lm\n",
    "    print(\"✓ mlx_lm installed successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ mlx_lm error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c05722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPU Test ===\n",
      "Default device: Device(gpu, 0)\n",
      "Metal available: True\n",
      "\n",
      "Creating 10000x10000 matrix multiplication...\n",
      "GPU computation time: 0.306 seconds\n",
      "GPU memory used: 1.12 GB\n",
      "GPU memory cache: 0.00 GB\n",
      "\n",
      "=== Testing Model Loading ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mx.metal.get_active_memory is deprecated and will be removed in a future version. Use mx.get_active_memory instead.\n",
      "mx.metal.get_cache_memory is deprecated and will be removed in a future version. Use mx.get_cache_memory instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec3e0418dfa42ff86e75655a2d553be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded successfully\n",
      "✗ Model loading error: 'TokenizerWrapper' object is not callable\n",
      "This is okay for now - we'll use a different model for distributed tests\n"
     ]
    }
   ],
   "source": [
    "import mlx.core as mx\n",
    "import time\n",
    "\n",
    "# Set GPU as default device\n",
    "mx.set_default_device(mx.gpu)\n",
    "\n",
    "print(\"=== GPU Test ===\")\n",
    "print(f\"Default device: {mx.default_device()}\")\n",
    "print(f\"Metal available: {mx.metal.is_available()}\")\n",
    "\n",
    "# Create a large array to test GPU\n",
    "size = 10000\n",
    "print(f\"\\nCreating {size}x{size} matrix multiplication...\")\n",
    "\n",
    "# Time CPU vs GPU\n",
    "start = time.time()\n",
    "a = mx.random.uniform(shape=(size, size))\n",
    "b = mx.random.uniform(shape=(size, size))\n",
    "c = a @ b\n",
    "mx.eval(c)  # Force evaluation\n",
    "gpu_time = time.time() - start\n",
    "\n",
    "print(f\"GPU computation time: {gpu_time:.3f} seconds\")\n",
    "print(f\"GPU memory used: {mx.metal.get_active_memory() / 1024**3:.2f} GB\")\n",
    "print(f\"GPU memory cache: {mx.metal.get_cache_memory() / 1024**3:.2f} GB\")\n",
    "\n",
    "# Test small model loading\n",
    "print(\"\\n=== Testing Model Loading ===\")\n",
    "try:\n",
    "    from mlx_lm import load\n",
    "    model, tokenizer = load(\"mlx-community/Llama-3.2-1B-Instruct-4bit\")\n",
    "    print(\"✓ Model loaded successfully\")\n",
    "    \n",
    "    # Quick inference test\n",
    "    prompt = \"Hello\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"np\")\n",
    "    print(f\"✓ Tokenizer works: '{prompt}' -> {inputs['input_ids']}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Model loading error: {e}\")\n",
    "    print(\"This is okay for now - we'll use a different model for distributed tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cd0158c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing SSH Connectivity ===\n",
      "\n",
      "Testing mm@mm1.local...\n",
      "✓ SSH connection successful\n",
      "\n",
      "Testing mm@mm2.local...\n",
      "✓ SSH connection successful\n",
      "\n",
      "=== Recommended SSH Config ===\n",
      "Add this to ~/.ssh/config:\n",
      "\n",
      "Host mm1.local\n",
      "    User mm\n",
      "    HostName mm1.local\n",
      "    ForwardAgent yes\n",
      "    ServerAliveInterval 60\n",
      "\n",
      "Host mm2.local\n",
      "    User mm\n",
      "    HostName mm2.local\n",
      "    ForwardAgent yes\n",
      "    ServerAliveInterval 60\n",
      "\n",
      "Host *\n",
      "    AddKeysToAgent yes\n",
      "    UseKeychain yes\n",
      "    IdentityFile ~/.ssh/id_rsa\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "hosts = [\"mm@mm1.local\", \"mm@mm2.local\"]\n",
    "\n",
    "print(\"=== Testing SSH Connectivity ===\")\n",
    "for host in hosts:\n",
    "    print(f\"\\nTesting {host}...\")\n",
    "    \n",
    "    # Test basic SSH\n",
    "    result = subprocess.run(\n",
    "        [\"ssh\", \"-o\", \"BatchMode=yes\", \"-o\", \"ConnectTimeout=5\", host, \"echo 'SSH OK'\"],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"✓ SSH connection successful\")\n",
    "    else:\n",
    "        print(f\"✗ SSH connection failed: {result.stderr}\")\n",
    "        print(f\"  Fix: Run 'ssh-copy-id {host}' in terminal\")\n",
    "\n",
    "# Create SSH config for faster connections\n",
    "ssh_config = \"\"\"\n",
    "Host mm1.local\n",
    "    User mm\n",
    "    HostName mm1.local\n",
    "    ForwardAgent yes\n",
    "    ServerAliveInterval 60\n",
    "\n",
    "Host mm2.local\n",
    "    User mm\n",
    "    HostName mm2.local\n",
    "    ForwardAgent yes\n",
    "    ServerAliveInterval 60\n",
    "\n",
    "Host *\n",
    "    AddKeysToAgent yes\n",
    "    UseKeychain yes\n",
    "    IdentityFile ~/.ssh/id_rsa\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n=== Recommended SSH Config ===\")\n",
    "print(\"Add this to ~/.ssh/config:\")\n",
    "print(ssh_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4a87e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Local MPI (2 processes) ===\n",
      "Output:\n",
      "\n",
      "Errors:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zz/Documents/GitHub/mlx-dist-setup/test_mpi_local.py\", line 4, in <module>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zz/Documents/GitHub/mlx-dist-setup/test_mpi_local.py\", line 4, in <module>\n",
      "    from mpi4py import MPI\n",
      "    from mpi4py import MPI\n",
      "ImportError: dlopen(/Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/MPI.cpython-311-darwin.so, 0x0002): Library not loaded: @rpath/libmpi.40.dylib\n",
      "  Referenced from: <A853210E-CFB8-34D9-8C29-289BC747DD98> /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/MPI.cpython-311-darwin.so\n",
      "  Reason: tried: '/Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/../../../libmpi.40.dylib' (no such file), '/Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/../../../libmpi.40.dylib' (no such file), '/Users/zz/anaconda3/envs/mlx-distributed/bin/../lib/libmpi.40.dylib' (no such file), '/Users/zz/anaconda3/envs/mlx-distributed/bin/../lib/libmpi.40.dylib' (no such file), '/usr/local/lib/libmpi.40.dylib' (no such file), '/usr/lib/libmpi.40.dylib' (no such file, not in dyld cache)\n",
      "ImportError: dlopen(/Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/MPI.cpython-311-darwin.so, 0x0002): Library not loaded: @rpath/libmpi.40.dylib\n",
      "  Referenced from: <A853210E-CFB8-34D9-8C29-289BC747DD98> /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/MPI.cpython-311-darwin.so\n",
      "  Reason: tried: '/Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/../../../libmpi.40.dylib' (no such file), '/Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/../../../libmpi.40.dylib' (no such file), '/Users/zz/anaconda3/envs/mlx-distributed/bin/../lib/libmpi.40.dylib' (no such file), '/Users/zz/anaconda3/envs/mlx-distributed/bin/../lib/libmpi.40.dylib' (no such file), '/usr/local/lib/libmpi.40.dylib' (no such file), '/usr/lib/libmpi.40.dylib' (no such file, not in dyld cache)\n",
      "--------------------------------------------------------------------------\n",
      "prterun detected that one or more processes exited with non-zero status,\n",
      "thus causing the job to be terminated. The first process to do so was:\n",
      "\n",
      "   Process name: [prterun-mbp-31871@1,1]\n",
      "   Exit code:    1\n",
      "--------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a test MPI script\n",
    "test_script = \"\"\"\n",
    "import os\n",
    "import socket\n",
    "from mpi4py import MPI\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "pid = os.getpid()\n",
    "\n",
    "print(f\"Rank {rank}/{size} on {hostname} (PID: {pid})\")\n",
    "\n",
    "# Test communication\n",
    "if rank == 0:\n",
    "    data = {'message': 'Hello from rank 0!'}\n",
    "    comm.send(data, dest=1)\n",
    "    print(f\"Rank 0: Sent message to rank 1\")\n",
    "elif rank == 1:\n",
    "    data = comm.recv(source=0)\n",
    "    print(f\"Rank 1: Received: {data['message']}\")\n",
    "\n",
    "comm.Barrier()\n",
    "if rank == 0:\n",
    "    print(\"All processes synchronized successfully!\")\n",
    "\"\"\"\n",
    "\n",
    "# Write test script\n",
    "with open('test_mpi_local.py', 'w') as f:\n",
    "    f.write(test_script)\n",
    "\n",
    "print(\"=== Testing Local MPI (2 processes) ===\")\n",
    "result = subprocess.run(\n",
    "    ['mpirun', '-np', '2', sys.executable, 'test_mpi_local.py'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "# Clean up\n",
    "os.remove('test_mpi_local.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cd038fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ mpi4py is installed in current Python: /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mpi4py/__init__.py\n",
      "  mpi4py version: 3.1.4\n",
      "\n",
      "Current Python: /Users/zz/anaconda3/envs/mlx-distributed/bin/python\n",
      "Python version: 3.11.13 (main, Jun  5 2025, 08:21:08) [Clang 14.0.6 ]\n",
      "\n",
      "✓ mpi4py 3.1.4 is installed via pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kg/kcthhx557hn1f2c_70pvhfvm0000gn/T/ipykernel_28766/944779985.py:17: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Conda list output:\n",
      "# packages in environment at /Users/zz/anaconda3/envs/mlx-distributed:\n",
      "#\n",
      "# Name                     Version          Build            Channel\n",
      "mpi4py                     3.1.4            py311he4f2fd2_0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Check if mpi4py is installed in current environment\n",
    "try:\n",
    "    import mpi4py\n",
    "    print(f\"✓ mpi4py is installed in current Python: {mpi4py.__file__}\")\n",
    "    print(f\"  mpi4py version: {mpi4py.__version__}\")\n",
    "except ImportError:\n",
    "    print(\"✗ mpi4py not found in current Python\")\n",
    "\n",
    "# Check which Python we're using\n",
    "print(f\"\\nCurrent Python: {sys.executable}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "\n",
    "# Better way to check installed packages\n",
    "try:\n",
    "    import pkg_resources\n",
    "    installed_packages = [d.project_name for d in pkg_resources.working_set]\n",
    "    if 'mpi4py' in installed_packages:\n",
    "        version = pkg_resources.get_distribution('mpi4py').version\n",
    "        print(f\"\\n✓ mpi4py {version} is installed via pip\")\n",
    "    else:\n",
    "        print(\"\\n✗ mpi4py not found in pip packages\")\n",
    "except:\n",
    "    # Alternative method\n",
    "    import importlib.metadata\n",
    "    try:\n",
    "        version = importlib.metadata.version('mpi4py')\n",
    "        print(f\"\\n✓ mpi4py {version} is installed\")\n",
    "    except:\n",
    "        print(\"\\n✗ mpi4py not installed\")\n",
    "\n",
    "# Check conda list instead\n",
    "import subprocess\n",
    "result = subprocess.run(['conda', 'list', 'mpi4py'], capture_output=True, text=True)\n",
    "print(f\"\\nConda list output:\\n{result.stdout}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "580f8dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Running with python -m mpi4py ===\n",
      "Output: \n",
      "Errors: Unknown option: -n\n",
      "usage: python -m mpi4py [options] <pyfile> [arg] ...\n",
      "   or: python -m mpi4py [options] -m <mod> [arg] ...\n",
      "   or: python -m mpi4py [options] -c <cmd> [arg] ...\n",
      "   or: python -m mpi4py [options] - [arg] ...\n",
      "Try `python -m mpi4py -h` for more information.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# Use the -m flag to ensure Python uses the right module path\n",
    "test_code = '''\n",
    "import sys\n",
    "print(f\"Python: {sys.executable}\")\n",
    "try:\n",
    "    import mpi4py\n",
    "    print(f\"mpi4py location: {mpi4py.__file__}\")\n",
    "    from mpi4py import MPI\n",
    "    print(f\"Rank {MPI.COMM_WORLD.rank}: Success!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "'''\n",
    "\n",
    "# Save test script\n",
    "with open('simple_mpi_test.py', 'w') as f:\n",
    "    f.write(test_code)\n",
    "\n",
    "# Run with python -m mpi4py\n",
    "print(\"=== Running with python -m mpi4py ===\")\n",
    "result = subprocess.run(\n",
    "    [sys.executable, '-m', 'mpi4py', '-n', '2', 'simple_mpi_test.py'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "print(\"Output:\", result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)\n",
    "\n",
    "os.remove('simple_mpi_test.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "304fc6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Solution: Use Homebrew MPI ===\n",
      "1. Removing broken mpi4py...\n",
      "Found existing installation: mpi4py 3.1.4\n",
      "Uninstalling mpi4py-3.1.4:\n",
      "  Successfully uninstalled mpi4py-3.1.4\n",
      "\n",
      "2. Installing mpi4py with Homebrew MPI...\n",
      "✓ mpi4py installed successfully\n",
      "\n",
      "3. Testing MPI...\n",
      "\n",
      "Output:\n",
      "Python: /Users/zz/anaconda3/envs/mlx-distributed/bin/python\n",
      "Python: /Users/zz/anaconda3/envs/mlx-distributed/bin/python\n",
      "Rank 1/2: MPI is working!\n",
      "Rank 0/2: MPI is working!\n",
      "Rank 1 received: Hello from rank 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=== Solution: Use Homebrew MPI ===\")\n",
    "\n",
    "# First, uninstall the broken mpi4py\n",
    "print(\"1. Removing broken mpi4py...\")\n",
    "subprocess.run([sys.executable, '-m', 'pip', 'uninstall', 'mpi4py', '-y'])\n",
    "\n",
    "# Install mpi4py compiled against Homebrew's MPI\n",
    "print(\"\\n2. Installing mpi4py with Homebrew MPI...\")\n",
    "env = os.environ.copy()\n",
    "env['MPICC'] = '/opt/homebrew/bin/mpicc'\n",
    "env['CC'] = '/opt/homebrew/bin/mpicc'\n",
    "\n",
    "result = subprocess.run(\n",
    "    [sys.executable, '-m', 'pip', 'install', 'mpi4py', '--no-cache-dir', '--no-binary', 'mpi4py'],\n",
    "    capture_output=True, text=True, env=env\n",
    ")\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"✓ mpi4py installed successfully\")\n",
    "else:\n",
    "    print(f\"Installation output: {result.stdout}\")\n",
    "    print(f\"Errors: {result.stderr}\")\n",
    "\n",
    "# Test the installation\n",
    "print(\"\\n3. Testing MPI...\")\n",
    "test_script = \"\"\"\n",
    "import sys\n",
    "print(f\"Python: {sys.executable}\")\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "print(f\"Rank {rank}/{size}: MPI is working!\")\n",
    "\n",
    "if rank == 0 and size > 1:\n",
    "    comm.send(\"Hello from rank 0\", dest=1)\n",
    "elif rank == 1:\n",
    "    msg = comm.recv(source=0)\n",
    "    print(f\"Rank 1 received: {msg}\")\n",
    "\"\"\"\n",
    "\n",
    "with open('test_mpi_final.py', 'w') as f:\n",
    "    f.write(test_script)\n",
    "\n",
    "# Run with Homebrew's mpirun\n",
    "result = subprocess.run(\n",
    "    ['/opt/homebrew/bin/mpirun', '-np', '2', sys.executable, 'test_mpi_final.py'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "print(\"\\nOutput:\")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)\n",
    "\n",
    "os.remove('test_mpi_final.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d333eec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Configuration Created ===\n",
      "Source this before running distributed jobs:\n",
      "  source mlx_dist_config.sh\n"
     ]
    }
   ],
   "source": [
    "# Create configuration for using Homebrew MPI\n",
    "config_content = f\"\"\"#!/bin/bash\n",
    "# MLX Distributed Configuration\n",
    "\n",
    "# Use Homebrew MPI\n",
    "export PATH=\"/opt/homebrew/bin:$PATH\"\n",
    "export MPICC=/opt/homebrew/bin/mpicc\n",
    "export MPIRUN=/opt/homebrew/bin/mpirun\n",
    "\n",
    "# Python from conda environment\n",
    "export PYTHON={sys.executable}\n",
    "\n",
    "# Function to run distributed MLX\n",
    "run_mlx_dist() {{\n",
    "    /opt/homebrew/bin/mpirun \"$@\"\n",
    "}}\n",
    "\n",
    "echo \"MLX Distributed configured with:\"\n",
    "echo \"  MPI: Homebrew OpenMPI 5.0.7\"\n",
    "echo \"  Python: Conda environment (mlx-distributed)\"\n",
    "echo \"\"\n",
    "echo \"Usage: run_mlx_dist -np 4 python your_script.py\"\n",
    "\"\"\"\n",
    "\n",
    "with open('mlx_dist_config.sh', 'w') as f:\n",
    "    f.write(config_content)\n",
    "\n",
    "os.chmod('mlx_dist_config.sh', 0o755)\n",
    "\n",
    "print(\"\\n=== Configuration Created ===\")\n",
    "print(\"Source this before running distributed jobs:\")\n",
    "print(\"  source mlx_dist_config.sh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d362527d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing MLX Distributed with Working MPI ===\n",
      "Output:\n",
      "Rank 0/1 on mbp\n",
      "  Python: /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mlx/core.cpython-311-darwin.so\n",
      "  Device: Device(gpu, 0)\n",
      "  Metal available: TrueRank 0/1 on mbp\n",
      "  Python: /Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mlx/core.cpython-311-darwin.so\n",
      "  Device: Device(gpu, 0)\n",
      "  Metal available: True\n",
      "\n",
      "\n",
      "Distributed sum: 0.0 (expected: 0)\n",
      "✓ MLX distributed test passed!\n",
      "Distributed sum: 0.0 (expected: 0)\n",
      "✓ MLX distributed test passed!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"=== Testing MLX Distributed with Working MPI ===\")\n",
    "\n",
    "# Create MLX distributed test\n",
    "mlx_test = \"\"\"\n",
    "import mlx.core as mx\n",
    "import socket\n",
    "\n",
    "# Initialize distributed\n",
    "world = mx.distributed.init()\n",
    "rank = world.rank()\n",
    "size = world.size()\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "# Set GPU device\n",
    "mx.set_default_device(mx.gpu)\n",
    "\n",
    "print(f\"Rank {rank}/{size} on {hostname}\")\n",
    "print(f\"  Python: {mx.__file__}\")\n",
    "print(f\"  Device: {mx.default_device()}\")\n",
    "print(f\"  Metal available: {mx.metal.is_available()}\")\n",
    "\n",
    "# Test distributed operation\n",
    "local_value = mx.array([float(rank)])\n",
    "sum_value = mx.distributed.all_sum(local_value)\n",
    "mx.eval(sum_value)\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"\\\\nDistributed sum: {sum_value.item()} (expected: {sum(range(size))})\")\n",
    "    print(\"✓ MLX distributed test passed!\")\n",
    "\"\"\"\n",
    "\n",
    "with open('test_mlx_distributed.py', 'w') as f:\n",
    "    f.write(mlx_test)\n",
    "\n",
    "# Run with Homebrew mpirun\n",
    "result = subprocess.run(\n",
    "    ['/opt/homebrew/bin/mpirun', '-np', '2', sys.executable, 'test_mlx_distributed.py'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"\\nErrors:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "os.remove('test_mlx_distributed.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "271ffb35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing MLX Distributed with MPI Backend ===\n",
      "Output:\n",
      "Rank 0/1 on mbp\n",
      "  Device: Device(gpu, 0)\n",
      "  GPU active: TrueRank 0/1 on mbp\n",
      "  Device: Device(gpu, 0)\n",
      "  GPU active: True\n",
      "  Local value: 0.0\n",
      "\n",
      "  Local value: 0.0\n",
      "  Sum result: 0.0\n",
      "  Sum result: 0.0\n",
      "\n",
      "Final: Distributed sum = 0.0 (expected: 0)\n",
      "\n",
      "Final: Distributed sum = 0.0 (expected: 0)\n",
      "✓ MLX distributed test PASSED!✓ MLX distributed test PASSED!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"=== Testing MLX Distributed with MPI Backend ===\")\n",
    "\n",
    "# Create a test that explicitly uses MPI backend\n",
    "mlx_mpi_test = \"\"\"\n",
    "import os\n",
    "import mlx.core as mx\n",
    "import socket\n",
    "\n",
    "# IMPORTANT: Set environment variable before importing\n",
    "os.environ['MLX_DISTRIBUTED_BACKEND'] = 'mpi'\n",
    "\n",
    "# Initialize distributed with explicit backend\n",
    "world = mx.distributed.init(backend='mpi')\n",
    "rank = world.rank()\n",
    "size = world.size()\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "print(f\"Rank {rank}/{size} on {hostname}\")\n",
    "print(f\"  Device: {mx.default_device()}\")\n",
    "\n",
    "# Set GPU after init\n",
    "mx.set_default_device(mx.gpu)\n",
    "print(f\"  GPU active: {mx.metal.is_available()}\")\n",
    "\n",
    "# Test distributed operation\n",
    "local_value = mx.array([float(rank)])\n",
    "print(f\"  Local value: {local_value.item()}\")\n",
    "\n",
    "# All-reduce sum\n",
    "sum_value = mx.distributed.all_sum(local_value)\n",
    "mx.eval(sum_value)\n",
    "\n",
    "print(f\"  Sum result: {sum_value.item()}\")\n",
    "\n",
    "if rank == 0:\n",
    "    expected = sum(range(size))\n",
    "    print(f\"\\\\nFinal: Distributed sum = {sum_value.item()} (expected: {expected})\")\n",
    "    if abs(sum_value.item() - expected) < 0.001:\n",
    "        print(\"✓ MLX distributed test PASSED!\")\n",
    "    else:\n",
    "        print(\"✗ MLX distributed test FAILED!\")\n",
    "\"\"\"\n",
    "\n",
    "with open('test_mlx_mpi.py', 'w') as f:\n",
    "    f.write(mlx_mpi_test)\n",
    "\n",
    "# Run with environment variable\n",
    "env = os.environ.copy()\n",
    "env['MLX_DISTRIBUTED_BACKEND'] = 'mpi'\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['/opt/homebrew/bin/mpirun', '-np', '2', sys.executable, 'test_mlx_mpi.py'],\n",
    "    capture_output=True, text=True, env=env\n",
    ")\n",
    "\n",
    "print(\"Output:\")\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"\\nErrors:\")\n",
    "    print(result.stderr)\n",
    "\n",
    "os.remove('test_mlx_mpi.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65951898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing with mlx.launch ===\n",
      "1. Testing locally with 2 processes:\n",
      "\n",
      "Errors: /Users/zz/anaconda3/envs/mlx-distributed/bin/python: No module named mlx.launch\n",
      "\n",
      "\n",
      "2. Testing with multiple hosts:\n",
      "Hosts: mbp.local,mm1.local,mm2.local\n",
      "\n",
      "Command: /Users/zz/anaconda3/envs/mlx-distributed/bin/python -m mlx.launch --hosts mbp.local,mm1.local,mm2.local test_mlx_launch.py\n",
      "\n",
      "Run this command to test distributed:\n",
      "/Users/zz/anaconda3/envs/mlx-distributed/bin/python -m mlx.launch --hosts mbp.local,mm1.local,mm2.local test_mlx_launch.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "print(\"=== Testing with mlx.launch ===\")\n",
    "\n",
    "# Create a proper MLX distributed test\n",
    "mlx_test = \"\"\"\n",
    "import mlx.core as mx\n",
    "import socket\n",
    "\n",
    "# Initialize distributed - mlx.launch will handle the backend\n",
    "world = mx.distributed.init()\n",
    "rank = world.rank()\n",
    "size = world.size()\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "# Set GPU\n",
    "mx.set_default_device(mx.gpu)\n",
    "\n",
    "print(f\"Rank {rank}/{size} on {hostname}\")\n",
    "print(f\"  GPU: {mx.metal.is_available()}\")\n",
    "\n",
    "# Test distributed operation\n",
    "local_value = mx.array([float(rank)])\n",
    "sum_value = mx.distributed.all_sum(local_value)\n",
    "mx.eval(sum_value)\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"\\\\nDistributed sum: {sum_value.item()} (expected: {sum(range(size))})\")\n",
    "    print(\"✓ MLX distributed works correctly!\")\n",
    "\"\"\"\n",
    "\n",
    "with open('test_mlx_launch.py', 'w') as f:\n",
    "    f.write(mlx_test)\n",
    "\n",
    "# Test locally first\n",
    "print(\"1. Testing locally with 2 processes:\")\n",
    "result = subprocess.run(\n",
    "    [sys.executable, '-m', 'mlx.launch', '--np', '2', 'test_mlx_launch.py'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)\n",
    "\n",
    "# Create test for multiple hosts\n",
    "print(\"\\n2. Testing with multiple hosts:\")\n",
    "\n",
    "# Create hostfile\n",
    "hosts = \"mbp.local,mm1.local,mm2.local\"\n",
    "print(f\"Hosts: {hosts}\")\n",
    "\n",
    "# Command for distributed run\n",
    "cmd = [sys.executable, '-m', 'mlx.launch', '--hosts', hosts, 'test_mlx_launch.py']\n",
    "print(f\"\\nCommand: {' '.join(cmd)}\")\n",
    "print(\"\\nRun this command to test distributed:\")\n",
    "print(' '.join(cmd))\n",
    "\n",
    "os.remove('test_mlx_launch.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "633a130a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checking for MLX launch tools ===\n",
      "Found mlx.launch command at: /Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch\n",
      "\n",
      "=== Checking MLX modules ===\n",
      "MLX location: None\n",
      "Error: expected str, bytes or os.PathLike object, not NoneType\n",
      "\n",
      "=== Checking mlx_lm.launch ===\n",
      "mlx_lm.launch error: /Users/zz/anaconda3/envs/mlx-distributed/bin/python: No module named mlx_lm.launch\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"=== Checking for MLX launch tools ===\")\n",
    "\n",
    "# Check if mlx.launch exists as a command\n",
    "result = subprocess.run(['which', 'mlx.launch'], capture_output=True, text=True)\n",
    "if result.stdout:\n",
    "    print(f\"Found mlx.launch command at: {result.stdout.strip()}\")\n",
    "else:\n",
    "    print(\"mlx.launch command not found in PATH\")\n",
    "\n",
    "# Check MLX installation for launch capabilities\n",
    "print(\"\\n=== Checking MLX modules ===\")\n",
    "try:\n",
    "    import mlx\n",
    "    print(f\"MLX location: {mlx.__file__}\")\n",
    "    \n",
    "    # List MLX submodules\n",
    "    mlx_dir = os.path.dirname(mlx.__file__)\n",
    "    print(f\"\\nMLX modules in {mlx_dir}:\")\n",
    "    for item in os.listdir(mlx_dir):\n",
    "        if not item.startswith('_') and (item.endswith('.py') or os.path.isdir(os.path.join(mlx_dir, item))):\n",
    "            print(f\"  {item}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Check for mlx_lm.launch which was mentioned earlier\n",
    "print(\"\\n=== Checking mlx_lm.launch ===\")\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [sys.executable, '-m', 'mlx_lm.launch', '--help'],\n",
    "        capture_output=True, text=True\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"✓ mlx_lm.launch is available!\")\n",
    "        print(\"Usage:\", result.stdout.split('\\n')[0])\n",
    "    else:\n",
    "        print(\"mlx_lm.launch error:\", result.stderr)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "be40f90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing with Official mlx.launch ===\n",
      "1. Getting mlx.launch options:\n",
      "usage: mlx.launch [-h] [--print-python] [--verbose] [--hosts HOSTS]\n",
      "                  [--repeat-hosts REPEAT_HOSTS] [--hostfile HOSTFILE]\n",
      "                  [--backend {ring,mpi}] [--env ENV] [--mpi-arg MPI_ARG]\n",
      "                  [--connections-per-ip CONNECTIONS_PER_IP]\n",
      "                  [--starting-port STARTING_PORT] [--cwd CWD]\n",
      "\n",
      "Launch an MLX distributed program\n",
      "\n",
      "options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --print-python        Print the path to the current python executable and\n",
      "                        exit\n",
      "  --verbose             Print debug messages in stdout\n",
      "  --hosts HOSTS         A comma separated list of hosts\n",
      "  --repeat-hosts REPEAT_HOSTS, -n REPEAT_HOSTS\n",
      "                        Repeat each host a given number of times\n",
      "  --hostfile HOSTFILE   The file containing the hosts\n",
      "  --backend {ring,mpi}  Which distributed backend to launch\n",
      "  --env ENV             Set environment variables for the jobs\n",
      "  --mpi-arg MPI_ARG     Arguments to pass directly to mpirun\n",
      "  --connections-per-ip CONNECTIONS_PER_IP\n",
      "                        How many connections per ip to use for the ring\n",
      "                        backend\n",
      "  --starting-port STARTING_PORT, -p STARTING_PORT\n",
      "                        For the ring backend listen on this port increasing by\n",
      "                        1 per rank and IP\n",
      "  --cwd CWD             Set the working directory on each node to the provided\n",
      "                        one\n",
      "\n",
      "\n",
      "2. Running with mlx.launch (2 processes):\n",
      "Command: /Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch --np 2 test_mlx_dist.py\n",
      "--------------------------------------------------\n",
      "\n",
      "Errors: Traceback (most recent call last):\n",
      "  File \"/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/Users/zz/anaconda3/envs/mlx-distributed/lib/python3.11/site-packages/mlx/distributed_run.py\", line 797, in main\n",
      "    raise ValueError(f\"Invalid script or command {rest[0]}\")\n",
      "ValueError: Invalid script or command --np\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Use the actual mlx.launch command\n",
    "mlx_launch = '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch'\n",
    "\n",
    "print(\"=== Testing with Official mlx.launch ===\")\n",
    "\n",
    "# First, let's see what options mlx.launch supports\n",
    "print(\"1. Getting mlx.launch options:\")\n",
    "result = subprocess.run([mlx_launch, '--help'], capture_output=True, text=True)\n",
    "print(result.stdout if result.stdout else result.stderr)\n",
    "\n",
    "# Create a proper test script\n",
    "test_script = \"\"\"\n",
    "import mlx.core as mx\n",
    "import socket\n",
    "\n",
    "# Initialize distributed\n",
    "world = mx.distributed.init()\n",
    "rank = world.rank()\n",
    "size = world.size()\n",
    "hostname = socket.gethostname()\n",
    "\n",
    "print(f\"Rank {rank}/{size} on {hostname}\")\n",
    "\n",
    "# Set GPU\n",
    "mx.set_default_device(mx.gpu)\n",
    "print(f\"  GPU: {mx.metal.is_available()}\")\n",
    "print(f\"  Device: {mx.default_device()}\")\n",
    "\n",
    "# Test distributed computation\n",
    "if size > 1:\n",
    "    local_value = mx.array([float(rank)])\n",
    "    print(f\"  Local value: {local_value.item()}\")\n",
    "    \n",
    "    # All-reduce sum\n",
    "    sum_value = mx.distributed.all_sum(local_value)\n",
    "    mx.eval(sum_value)\n",
    "    \n",
    "    if rank == 0:\n",
    "        expected = sum(range(size))\n",
    "        print(f\"\\\\nAll-reduce sum: {sum_value.item()} (expected: {expected})\")\n",
    "        success = abs(sum_value.item() - expected) < 0.001\n",
    "        print(f\"{'✓' if success else '✗'} Test {'PASSED' if success else 'FAILED'}!\")\n",
    "else:\n",
    "    print(\"\\\\n⚠️  Only 1 process - need multiple processes to test distributed ops\")\n",
    "\"\"\"\n",
    "\n",
    "with open('test_mlx_dist.py', 'w') as f:\n",
    "    f.write(test_script)\n",
    "\n",
    "# Test with mlx.launch\n",
    "print(\"\\n2. Running with mlx.launch (2 processes):\")\n",
    "cmd = [mlx_launch, '--np', '2', 'test_mlx_dist.py']\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fc900bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Trying Different mlx.launch Syntax ===\n",
      "\n",
      "Trying command 1: /Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch -n 2 test_mlx_dist.py\n",
      "✓ This syntax works!\n",
      "Rank 1/2 on mbp\n",
      "  GPU: True\n",
      "Rank 0/2 on mbp\n",
      "  GPU: True\n",
      "  Device: Device(gpu, 0)\n",
      "  Device: Device(gpu, 0)\n",
      "  Local value: 1.0\n",
      "  Local value: 0.0\n",
      "\n",
      "All-reduce sum: 1.0 (expected: 1)\n",
      "✓ Test PASSED!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Trying Different mlx.launch Syntax ===\")\n",
    "\n",
    "# Common MPI launcher syntaxes to try\n",
    "test_commands = [\n",
    "    [mlx_launch, '-n', '2', 'test_mlx_dist.py'],\n",
    "    [mlx_launch, '-np', '2', 'test_mlx_dist.py'], \n",
    "    [mlx_launch, '--nproc', '2', 'test_mlx_dist.py'],\n",
    "    [mlx_launch, '--backend', 'mpi', '-np', '2', 'test_mlx_dist.py'],\n",
    "]\n",
    "\n",
    "for i, cmd in enumerate(test_commands):\n",
    "    print(f\"\\nTrying command {i+1}: {' '.join(cmd)}\")\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    if result.returncode == 0 and \"Rank 1/2\" in result.stdout:\n",
    "        print(\"✓ This syntax works!\")\n",
    "        print(result.stdout)\n",
    "        break\n",
    "    elif result.returncode != 0:\n",
    "        print(f\"✗ Failed: {result.stderr.strip()[:100]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "361b8023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Using Correct mlx.launch Syntax ===\n",
      "1. Testing local with 2 processes:\n",
      "Command: /Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch --hosts localhost -n 2 test_mlx_dist.py\n",
      "--------------------------------------------------\n",
      "\n",
      "Errors: usage: mlx.launch [-h] [--print-python] [--verbose] [--hosts HOSTS]\n",
      "                  [--repeat-hosts REPEAT_HOSTS] [--hostfile HOSTFILE]\n",
      "                  [--backend {ring,mpi}] [--env ENV] [--mpi-arg MPI_ARG]\n",
      "                  [--connections-per-ip CONNECTIONS_PER_IP]\n",
      "                  [--starting-port STARTING_PORT] [--cwd CWD]\n",
      "mlx.launch: error: The ring backend requires IPs to be provided instead of hostnames\n",
      "\n",
      "\n",
      "2. Testing with MPI backend explicitly:\n",
      "Command: /Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch --backend mpi --hosts localhost -n 2 test_mlx_dist.py\n",
      "--------------------------------------------------\n",
      "Rank 0/2 on mbp\n",
      "Rank 1/2 on mbp\n",
      "  GPU: True\n",
      "  Device: Device(gpu, 0)\n",
      "  GPU: True\n",
      "  Device: Device(gpu, 0)\n",
      "  Local value: 0.0\n",
      "  Local value: 1.0\n",
      "\n",
      "All-reduce sum: 1.0 (expected: 1)\n",
      "✓ Test PASSED!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "mlx_launch = '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch'\n",
    "\n",
    "print(\"=== Using Correct mlx.launch Syntax ===\")\n",
    "\n",
    "# For local runs, we need to specify localhost and repeat it\n",
    "print(\"1. Testing local with 2 processes:\")\n",
    "cmd = [mlx_launch, '--hosts', 'localhost', '-n', '2', 'test_mlx_dist.py']\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)\n",
    "\n",
    "# Try with explicit backend\n",
    "print(\"\\n2. Testing with MPI backend explicitly:\")\n",
    "cmd = [mlx_launch, '--backend', 'mpi', '--hosts', 'localhost', '-n', '2', 'test_mlx_dist.py']\n",
    "print(f\"Command: {' '.join(cmd)}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "print(result.stdout)\n",
    "if result.stderr:\n",
    "    print(\"Errors:\", result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6c62cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Creating Correct Run Scripts ===\n",
      "Created scripts:\n",
      "1. ./run_mlx_local.sh [processes]    - Run locally\n",
      "2. ./run_mlx_cluster.sh              - Run on cluster (2 per host)\n",
      "3. ./run_mlx_hostfile.sh             - Run with hostfile\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Creating Correct Run Scripts ===\")\n",
    "\n",
    "# Local run script\n",
    "local_script = f\"\"\"#!/bin/bash\n",
    "# Run MLX distributed locally\n",
    "\n",
    "# Number of processes (default 2)\n",
    "NP=\"${{1:-2}}\"\n",
    "SCRIPT=\"${{2:-test_mlx_dist.py}}\"\n",
    "\n",
    "echo \"Running MLX with $NP local processes...\"\n",
    "echo \"Script: $SCRIPT\"\n",
    "echo \"\"\n",
    "\n",
    "# Use localhost repeated NP times\n",
    "{mlx_launch} --hosts localhost -n \"$NP\" \"$SCRIPT\"\n",
    "\"\"\"\n",
    "\n",
    "with open('run_mlx_local.sh', 'w') as f:\n",
    "    f.write(local_script)\n",
    "os.chmod('run_mlx_local.sh', 0o755)\n",
    "\n",
    "# Distributed run script for your cluster\n",
    "distributed_script = f\"\"\"#!/bin/bash\n",
    "# Run MLX distributed across your cluster\n",
    "\n",
    "SCRIPT=\"${{1:-test_mlx_dist.py}}\"\n",
    "\n",
    "# Option 1: Using comma-separated hosts with repetition\n",
    "echo \"=== Running distributed with 2 processes per host ===\"\n",
    "{mlx_launch} --hosts mbp.local,mm1.local,mm2.local -n 2 \"$SCRIPT\"\n",
    "\"\"\"\n",
    "\n",
    "with open('run_mlx_cluster.sh', 'w') as f:\n",
    "    f.write(distributed_script)\n",
    "os.chmod('run_mlx_cluster.sh', 0o755)\n",
    "\n",
    "# Create a hostfile version\n",
    "hostfile_content = \"\"\"mbp.local\n",
    "mbp.local\n",
    "mm1.local\n",
    "mm1.local\n",
    "mm2.local\n",
    "mm2.local\n",
    "\"\"\"\n",
    "\n",
    "with open('mlx_hostfile.txt', 'w') as f:\n",
    "    f.write(hostfile_content)\n",
    "\n",
    "hostfile_script = f\"\"\"#!/bin/bash\n",
    "# Run MLX using hostfile\n",
    "\n",
    "SCRIPT=\"${{1:-test_mlx_dist.py}}\"\n",
    "HOSTFILE=\"${{2:-mlx_hostfile.txt}}\"\n",
    "\n",
    "echo \"Running MLX with hostfile: $HOSTFILE\"\n",
    "cat \"$HOSTFILE\"\n",
    "echo \"\"\n",
    "\n",
    "{mlx_launch} --hostfile \"$HOSTFILE\" \"$SCRIPT\"\n",
    "\"\"\"\n",
    "\n",
    "with open('run_mlx_hostfile.sh', 'w') as f:\n",
    "    f.write(hostfile_script)\n",
    "os.chmod('run_mlx_hostfile.sh', 0o755)\n",
    "\n",
    "print(\"Created scripts:\")\n",
    "print(\"1. ./run_mlx_local.sh [processes]    - Run locally\")\n",
    "print(\"2. ./run_mlx_cluster.sh              - Run on cluster (2 per host)\")\n",
    "print(\"3. ./run_mlx_hostfile.sh             - Run with hostfile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e9e7c774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Creating Final Working Scripts ===\n",
      "Created working scripts!\n",
      "\n",
      "✅ Test locally first:\n",
      "   ./run_mlx_local.sh 4\n",
      "\n",
      "✅ Then run distributed:\n",
      "   ./run_mlx_distributed.sh\n",
      "   # This will run 2 processes on each of your 3 Macs (6 total)\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "mlx_launch = '/Users/zz/anaconda3/envs/mlx-distributed/bin/mlx.launch'\n",
    "\n",
    "print(\"=== Creating Final Working Scripts ===\")\n",
    "\n",
    "# Local run script with MPI backend\n",
    "local_script = f\"\"\"#!/bin/bash\n",
    "# Run MLX distributed locally with MPI backend\n",
    "\n",
    "NP=\"${{1:-2}}\"\n",
    "SCRIPT=\"${{2:-test_mlx_dist.py}}\"\n",
    "\n",
    "echo \"Running MLX locally with $NP processes (MPI backend)...\"\n",
    "echo \"Script: $SCRIPT\"\n",
    "echo \"\"\n",
    "\n",
    "{mlx_launch} --backend mpi --hosts localhost -n \"$NP\" \"$SCRIPT\"\n",
    "\"\"\"\n",
    "\n",
    "with open('run_mlx_local.sh', 'w') as f:\n",
    "    f.write(local_script)\n",
    "os.chmod('run_mlx_local.sh', 0o755)\n",
    "\n",
    "# Distributed run script for your cluster\n",
    "distributed_script = f\"\"\"#!/bin/bash\n",
    "# Run MLX distributed across your Mac cluster\n",
    "\n",
    "SCRIPT=\"${{1:-test_mlx_dist.py}}\"\n",
    "PROCESSES_PER_HOST=\"${{2:-2}}\"\n",
    "\n",
    "echo \"Running MLX distributed (MPI backend)\"\n",
    "echo \"Hosts: mbp.local, mm1.local, mm2.local\"\n",
    "echo \"Processes per host: $PROCESSES_PER_HOST\"\n",
    "echo \"Script: $SCRIPT\"\n",
    "echo \"\"\n",
    "\n",
    "{mlx_launch} --backend mpi \\\\\n",
    "    --hosts mbp.local,mm1.local,mm2.local \\\\\n",
    "    -n \"$PROCESSES_PER_HOST\" \\\\\n",
    "    \"$SCRIPT\"\n",
    "\"\"\"\n",
    "\n",
    "with open('run_mlx_distributed.sh', 'w') as f:\n",
    "    f.write(distributed_script)\n",
    "os.chmod('run_mlx_distributed.sh', 0o755)\n",
    "\n",
    "# Create hostfile for MPI backend\n",
    "hostfile_content = \"\"\"mbp.local\n",
    "mbp.local\n",
    "mm1.local\n",
    "mm1.local\n",
    "mm2.local\n",
    "mm2.local\n",
    "\"\"\"\n",
    "\n",
    "with open('mlx_hostfile.txt', 'w') as f:\n",
    "    f.write(hostfile_content)\n",
    "\n",
    "# Hostfile version\n",
    "hostfile_script = f\"\"\"#!/bin/bash\n",
    "# Run MLX using hostfile (MPI backend)\n",
    "\n",
    "SCRIPT=\"${{1:-test_mlx_dist.py}}\"\n",
    "HOSTFILE=\"${{2:-mlx_hostfile.txt}}\"\n",
    "\n",
    "echo \"Running MLX with hostfile (MPI backend)\"\n",
    "echo \"Hostfile: $HOSTFILE\"\n",
    "echo \"Script: $SCRIPT\"\n",
    "echo \"\"\n",
    "\n",
    "{mlx_launch} --backend mpi --hostfile \"$HOSTFILE\" \"$SCRIPT\"\n",
    "\"\"\"\n",
    "\n",
    "with open('run_mlx_hostfile.sh', 'w') as f:\n",
    "    f.write(hostfile_script)\n",
    "os.chmod('run_mlx_hostfile.sh', 0o755)\n",
    "\n",
    "print(\"Created working scripts!\")\n",
    "print(\"\\n✅ Test locally first:\")\n",
    "print(\"   ./run_mlx_local.sh 4\")\n",
    "print(\"\\n✅ Then run distributed:\")\n",
    "print(\"   ./run_mlx_distributed.sh\")\n",
    "print(\"   # This will run 2 processes on each of your 3 Macs (6 total)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "80f8687c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Setup Complete! ===\n",
      "\n",
      "🎉 MLX distributed is working correctly!\n",
      "\n",
      "Next steps:\n",
      "1. Test comprehensive script locally:\n",
      "   ./run_mlx_local.sh 4 test_mlx_comprehensive.py\n",
      "\n",
      "2. Deploy environment to mm1.local and mm2.local\n",
      "   (They need the same mlx-distributed conda environment)\n",
      "\n",
      "3. Run distributed across your cluster:\n",
      "   ./run_mlx_distributed.sh test_mlx_comprehensive.py\n",
      "\n",
      "This will run 6 processes total (2 on each Mac)\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive distributed test\n",
    "comprehensive_test = \"\"\"\n",
    "import mlx.core as mx\n",
    "import mlx.nn as nn\n",
    "import socket\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Initialize distributed\n",
    "world = mx.distributed.init()\n",
    "rank = world.rank()\n",
    "size = world.size()\n",
    "hostname = socket.gethostname()\n",
    "pid = os.getpid()\n",
    "\n",
    "# Set GPU\n",
    "mx.set_default_device(mx.gpu)\n",
    "\n",
    "print(f\"[Rank {rank}/{size}] Process {pid} on {hostname}\")\n",
    "print(f\"[Rank {rank}] GPU: {mx.metal.is_available()}\")\n",
    "print(f\"[Rank {rank}] Device: {mx.default_device()}\")\n",
    "\n",
    "# Synchronize before tests\n",
    "mx.eval(mx.distributed.all_sum(mx.array([1.0])))\n",
    "\n",
    "if rank == 0:\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"Running MLX Distributed Tests\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# Test 1: Basic all-reduce\n",
    "if rank == 0:\n",
    "    print(\"\\\\n1. Testing all-reduce...\")\n",
    "    \n",
    "local_value = mx.array([float(rank)])\n",
    "sum_result = mx.distributed.all_sum(local_value)\n",
    "mx.eval(sum_result)\n",
    "\n",
    "if rank == 0:\n",
    "    expected = sum(range(size))\n",
    "    print(f\"   All-reduce sum: {sum_result.item()} (expected: {expected})\")\n",
    "    print(f\"   {'✓ PASSED' if abs(sum_result.item() - expected) < 0.001 else '✗ FAILED'}\")\n",
    "\n",
    "# Test 2: Model parameter synchronization\n",
    "if rank == 0:\n",
    "    print(\"\\\\n2. Testing model parameter sync...\")\n",
    "\n",
    "model = nn.Linear(100, 10)\n",
    "mx.eval(model.parameters())\n",
    "\n",
    "# Get initial param sum\n",
    "param_sum_before = sum(p.sum().item() for _, p in model.parameters())\n",
    "print(f\"[Rank {rank}] Initial param sum: {param_sum_before:.6f}\")\n",
    "\n",
    "# Synchronize parameters\n",
    "for _, p in model.parameters():\n",
    "    p_synced = mx.distributed.all_sum(p) / size\n",
    "    p[:] = p_synced\n",
    "\n",
    "mx.eval(model.parameters())\n",
    "param_sum_after = sum(p.sum().item() for _, p in model.parameters())\n",
    "\n",
    "# All ranks should have same param sum now\n",
    "all_sums = mx.distributed.all_sum(mx.array([param_sum_after]))\n",
    "mx.eval(all_sums)\n",
    "\n",
    "if rank == 0:\n",
    "    print(f\"   Synchronized param sum: {param_sum_after:.6f}\")\n",
    "    print(f\"   {'✓ PASSED' if all_sums.item() == param_sum_after * size else '✗ FAILED'}\")\n",
    "\n",
    "# Test 3: Bandwidth test\n",
    "if rank == 0:\n",
    "    print(\"\\\\n3. Testing bandwidth...\")\n",
    "\n",
    "size_mb = 10\n",
    "data = mx.random.uniform(shape=(size_mb * 1024 * 1024 // 4,))\n",
    "\n",
    "start = time.time()\n",
    "result = mx.distributed.all_sum(data)\n",
    "mx.eval(result)\n",
    "elapsed = time.time() - start\n",
    "\n",
    "bandwidth = size_mb * size / elapsed\n",
    "if rank == 0:\n",
    "    print(f\"   Data size: {size_mb}MB per rank\")\n",
    "    print(f\"   Time: {elapsed:.3f}s\")\n",
    "    print(f\"   Bandwidth: {bandwidth:.1f} MB/s\")\n",
    "\n",
    "# Final status\n",
    "mx.eval(mx.distributed.all_sum(mx.array([1.0])))  # Sync\n",
    "if rank == 0:\n",
    "    print(\"\\\\n\" + \"=\"*50)\n",
    "    print(\"✓ All tests completed successfully!\")\n",
    "    print(\"=\"*50)\n",
    "\"\"\"\n",
    "\n",
    "with open('test_mlx_comprehensive.py', 'w') as f:\n",
    "    f.write(comprehensive_test)\n",
    "\n",
    "print(\"\\n=== Setup Complete! ===\")\n",
    "print(\"\\n🎉 MLX distributed is working correctly!\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Test comprehensive script locally:\")\n",
    "print(\"   ./run_mlx_local.sh 4 test_mlx_comprehensive.py\")\n",
    "print(\"\\n2. Deploy environment to mm1.local and mm2.local\")\n",
    "print(\"   (They need the same mlx-distributed conda environment)\")\n",
    "print(\"\\n3. Run distributed across your cluster:\")\n",
    "print(\"   ./run_mlx_distributed.sh test_mlx_comprehensive.py\")\n",
    "print(\"\\nThis will run 6 processes total (2 on each Mac)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlx-distributed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
